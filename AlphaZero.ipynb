{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martillopart/AutoML_Zero_Game/blob/main/AlphaZero.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "lg0NcA-SeeA8"
      },
      "id": "lg0NcA-SeeA8"
    },
    {
      "cell_type": "code",
      "source": [
        "CHOOSE_GAME = \"TicTacToe\" # @param [\"ConnectFour\", \"TicTacToe\", \"MartisGame\"]\n",
        "\n",
        "# @markdown Enable long & interactive tests if you want to thoroughly test the notebook; during normal development, you would typically run them once in a while to make sure everything still works.\n",
        "RUN_LONG_TESTS = False # @param {type:\"boolean\"}\n",
        "RUN_INTERACTIVE_TESTS = False # @param {type:\"boolean\"}"
      ],
      "metadata": {
        "id": "kg1qsIq-edPl"
      },
      "id": "kg1qsIq-edPl",
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\n",
        "    \"TicTacToe\": {\n",
        "        \"model\": \"model_2.pt\",\n",
        "        \"ResNet\": {\n",
        "            \"num_resBlocks\": 4,\n",
        "            \"num_hidden\": 64,\n",
        "        }\n",
        "    },\n",
        "    \"ConnectFour\": {\n",
        "        \"model\": \"model_7_ConnectFour.pt\",\n",
        "        \"ResNet\": {\n",
        "            \"num_resBlocks\": 9,\n",
        "            \"num_hidden\": 128,\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "assert CHOOSE_GAME in CONFIG"
      ],
      "metadata": {
        "id": "E227f7sTMQGU"
      },
      "id": "E227f7sTMQGU",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print cell execution time for every cell\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skOntXD6iIh8",
        "outputId": "843f70fc-5c4a-4df4-c4cc-bed67fe4c68e"
      },
      "id": "skOntXD6iIh8",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->ipython-autotime)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.13)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.2 jedi-0.19.1\n",
            "time: 342 µs (started: 2024-03-28 14:00:03 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notarize environmental properties"
      ],
      "metadata": {
        "id": "e30XDYNAdAuI"
      },
      "id": "e30XDYNAdAuI"
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n",
        "\n",
        "!pip install torch\n",
        "!pip install psutil\n",
        "\n",
        "import torch\n",
        "import psutil\n",
        "\n",
        "# Function to convert bytes to GB\n",
        "def bytes_to_gb(bytes_value):\n",
        "    return round(bytes_value / (1024**3), 2)\n",
        "\n",
        "# Check if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    # Get the name of the GPU device\n",
        "    device_name = torch.cuda.get_device_name(0)\n",
        "    print(\"GPU Make and Model: \", device_name)\n",
        "\n",
        "    # Get the GPU VRAM amount\n",
        "    gpu_vram = torch.cuda.get_device_properties(0).total_memory\n",
        "    print(\"GPU VRAM Amount: {} GB\".format(bytes_to_gb(gpu_vram)))\n",
        "else:\n",
        "    print(\"No GPU detected.\")\n",
        "\n",
        "# Get the CPU RAM amount\n",
        "cpu_ram = psutil.virtual_memory().total\n",
        "print(\"CPU RAM Amount: {} GB\".format(bytes_to_gb(cpu_ram)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FURBql5f0z1-",
        "outputId": "93a48368-3b07-46a4-ce12-e0c3457c1704"
      },
      "id": "FURBql5f0z1-",
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m52.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m57.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m78.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.99 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n",
            "GPU Make and Model:  Tesla V100-SXM2-16GB\n",
            "GPU VRAM Amount: 15.77 GB\n",
            "CPU RAM Amount: 50.99 GB\n",
            "time: 1min 15s (started: 2024-03-28 14:00:03 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the git repos and install dependencies"
      ],
      "metadata": {
        "id": "pWtaG7Q1xW5T"
      },
      "id": "pWtaG7Q1xW5T"
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/foersterrobert/AlphaZeroFromScratch\n",
        "! cp AlphaZeroFromScratch/*.pt .\n",
        "\n",
        "! git clone https://github.com/martillopart/AutoML_Zero_Game\n",
        "\n",
        "# XXX ERROR: Cannot uninstall 'blinker'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n",
        "! pip install -r AutoML_Zero_Game/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuoDlbdYxM4I",
        "outputId": "cfe33965-abc2-4cec-91f4-87cd517bb742"
      },
      "id": "tuoDlbdYxM4I",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AlphaZeroFromScratch'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 39 (delta 20), reused 13 (delta 13), pack-reused 15\u001b[K\n",
            "Receiving objects: 100% (39/39), 32.05 MiB | 26.24 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n",
            "Cloning into 'AutoML_Zero_Game'...\n",
            "remote: Enumerating objects: 124, done.\u001b[K\n",
            "remote: Counting objects: 100% (124/124), done.\u001b[K\n",
            "remote: Compressing objects: 100% (101/101), done.\u001b[K\n",
            "remote: Total 124 (delta 21), reused 120 (delta 20), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (124/124), 32.48 MiB | 20.22 MiB/s, done.\n",
            "Resolving deltas: 100% (21/21), done.\n",
            "Collecting asttokens==2.4.1 (from -r AutoML_Zero_Game/requirements.txt (line 1))\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: attrs==23.2.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 2)) (23.2.0)\n",
            "Collecting blinker==1.7.0 (from -r AutoML_Zero_Game/requirements.txt (line 3))\n",
            "  Downloading blinker-1.7.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: certifi==2024.2.2 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 4)) (2024.2.2)\n",
            "Requirement already satisfied: charset-normalizer==3.3.2 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 5)) (3.3.2)\n",
            "Requirement already satisfied: click==8.1.7 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 6)) (8.1.7)\n",
            "Collecting cloudpickle==3.0.0 (from -r AutoML_Zero_Game/requirements.txt (line 7))\n",
            "  Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
            "Collecting comm==0.2.2 (from -r AutoML_Zero_Game/requirements.txt (line 8))\n",
            "  Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: contourpy==1.2.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 9)) (1.2.0)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 10)) (0.12.1)\n",
            "Collecting decorator==5.1.1 (from -r AutoML_Zero_Game/requirements.txt (line 11))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: exceptiongroup==1.2.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 12)) (1.2.0)\n",
            "Collecting executing==2.0.1 (from -r AutoML_Zero_Game/requirements.txt (line 13))\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting Farama-Notifications==0.0.4 (from -r AutoML_Zero_Game/requirements.txt (line 14))\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: filelock==3.13.3 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 15)) (3.13.3)\n",
            "Collecting Flask==3.0.2 (from -r AutoML_Zero_Game/requirements.txt (line 16))\n",
            "  Downloading flask-3.0.2-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.3/101.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fonttools==4.50.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 17)) (4.50.0)\n",
            "Collecting fsspec==2024.3.1 (from -r AutoML_Zero_Game/requirements.txt (line 18))\n",
            "  Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gymnasium==0.29.0 (from -r AutoML_Zero_Game/requirements.txt (line 19))\n",
            "  Downloading gymnasium-0.29.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.8/953.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub==0.22.1 (from -r AutoML_Zero_Game/requirements.txt (line 20))\n",
            "  Downloading huggingface_hub-0.22.1-py3-none-any.whl (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.6/388.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna==3.6 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 21)) (3.6)\n",
            "Collecting ipython==8.22.2 (from -r AutoML_Zero_Game/requirements.txt (line 22))\n",
            "  Downloading ipython-8.22.2-py3-none-any.whl (811 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.0/812.0 kB\u001b[0m \u001b[31m22.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipywidgets==8.1.2 (from -r AutoML_Zero_Game/requirements.txt (line 23))\n",
            "  Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m17.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: itsdangerous==2.1.2 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 24)) (2.1.2)\n",
            "Requirement already satisfied: jedi==0.19.1 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 25)) (0.19.1)\n",
            "Requirement already satisfied: Jinja2==3.1.3 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 26)) (3.1.3)\n",
            "Collecting jsonschema==4.21.1 (from -r AutoML_Zero_Game/requirements.txt (line 27))\n",
            "  Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema-specifications==2023.12.1 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 28)) (2023.12.1)\n",
            "Requirement already satisfied: jupyterlab_widgets==3.0.10 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 29)) (3.0.10)\n",
            "Collecting kaggle-environments==1.14.3 (from -r AutoML_Zero_Game/requirements.txt (line 30))\n",
            "  Downloading kaggle_environments-1.14.3-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver==1.4.5 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 31)) (1.4.5)\n",
            "Requirement already satisfied: MarkupSafe==2.1.5 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 32)) (2.1.5)\n",
            "Collecting matplotlib==3.8.3 (from -r AutoML_Zero_Game/requirements.txt (line 33))\n",
            "  Downloading matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 34)) (0.1.6)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 35)) (1.3.0)\n",
            "Requirement already satisfied: networkx==3.2.1 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 36)) (3.2.1)\n",
            "Collecting numpy==1.26.4 (from -r AutoML_Zero_Game/requirements.txt (line 37))\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m66.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 38)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 39)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 40)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 41)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 42)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 43)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 44)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 45)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 46)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 47)) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.99 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 48)) (12.4.99)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 49)) (12.1.105)\n",
            "Requirement already satisfied: packaging==24.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 50)) (24.0)\n",
            "Collecting pandas==2.2.1 (from -r AutoML_Zero_Game/requirements.txt (line 51))\n",
            "  Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: parso==0.8.3 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 52)) (0.8.3)\n",
            "Collecting pettingzoo==1.24.0 (from -r AutoML_Zero_Game/requirements.txt (line 53))\n",
            "  Downloading pettingzoo-1.24.0-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pexpect==4.9.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 54)) (4.9.0)\n",
            "Collecting pillow==10.2.0 (from -r AutoML_Zero_Game/requirements.txt (line 55))\n",
            "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m80.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit==3.0.43 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 56)) (3.0.43)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 57)) (0.7.0)\n",
            "Collecting pure-eval==0.2.2 (from -r AutoML_Zero_Game/requirements.txt (line 58))\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting Pygments==2.17.2 (from -r AutoML_Zero_Game/requirements.txt (line 59))\n",
            "  Downloading pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m61.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing==3.1.2 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 60)) (3.1.2)\n",
            "Collecting python-dateutil==2.9.0.post0 (from -r AutoML_Zero_Game/requirements.txt (line 61))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz==2024.1 (from -r AutoML_Zero_Game/requirements.txt (line 62))\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML==6.0.1 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 63)) (6.0.1)\n",
            "Requirement already satisfied: referencing==0.34.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 64)) (0.34.0)\n",
            "Requirement already satisfied: regex==2023.12.25 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 65)) (2023.12.25)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 66)) (2.31.0)\n",
            "Requirement already satisfied: rpds-py==0.18.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 67)) (0.18.0)\n",
            "Requirement already satisfied: safetensors==0.4.2 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 68)) (0.4.2)\n",
            "Collecting scipy==1.12.0 (from -r AutoML_Zero_Game/requirements.txt (line 69))\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m39.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Shimmy==1.3.0 (from -r AutoML_Zero_Game/requirements.txt (line 70))\n",
            "  Downloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 71)) (1.16.0)\n",
            "Collecting stable-baselines3==2.1.0 (from -r AutoML_Zero_Game/requirements.txt (line 72))\n",
            "  Downloading stable_baselines3-2.1.0-py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m22.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stack-data==0.6.3 (from -r AutoML_Zero_Game/requirements.txt (line 73))\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: sympy==1.12 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 74)) (1.12)\n",
            "Requirement already satisfied: tokenizers==0.15.2 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 75)) (0.15.2)\n",
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 76)) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm==4.66.2 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 77)) (4.66.2)\n",
            "Collecting traitlets==5.14.2 (from -r AutoML_Zero_Game/requirements.txt (line 78))\n",
            "  Downloading traitlets-5.14.2-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m11.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.39.1 (from -r AutoML_Zero_Game/requirements.txt (line 79))\n",
            "  Downloading transformers-4.39.1-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m87.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 80)) (2.2.0)\n",
            "Requirement already satisfied: typing_extensions==4.10.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 81)) (4.10.0)\n",
            "Collecting tzdata==2024.1 (from -r AutoML_Zero_Game/requirements.txt (line 82))\n",
            "  Downloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m36.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3==2.2.1 (from -r AutoML_Zero_Game/requirements.txt (line 83))\n",
            "  Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m16.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting vec-noise==1.1.4 (from -r AutoML_Zero_Game/requirements.txt (line 84))\n",
            "  Downloading vec_noise-1.1.4.zip (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.1/134.1 kB\u001b[0m \u001b[31m18.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wcwidth==0.2.13 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 85)) (0.2.13)\n",
            "Requirement already satisfied: Werkzeug==3.0.1 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 86)) (3.0.1)\n",
            "Collecting widgetsnbextension==4.0.10 (from -r AutoML_Zero_Game/requirements.txt (line 87))\n",
            "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m93.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: vec-noise\n",
            "  Building wheel for vec-noise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vec-noise: filename=vec_noise-1.1.4-cp310-cp310-linux_x86_64.whl size=73651 sha256=916391beb27de85d9ef65b85102cc188e8e34626663c267f29c2919b58a06764\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/28/e4/f710af1a5bb24bb6da3d4f65081e268ca85034b7ac0a9237fe\n",
            "Successfully built vec-noise\n",
            "Installing collected packages: pytz, pure-eval, Farama-Notifications, widgetsnbextension, urllib3, tzdata, traitlets, python-dateutil, Pygments, pillow, numpy, fsspec, executing, decorator, cloudpickle, blinker, asttokens, vec-noise, stack-data, scipy, pandas, gymnasium, Flask, comm, Shimmy, pettingzoo, matplotlib, jsonschema, ipython, huggingface-hub, stable-baselines3, ipywidgets, transformers, kaggle-environments\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2023.4\n",
            "    Uninstalling pytz-2023.4:\n",
            "      Successfully uninstalled pytz-2023.4\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.6\n",
            "    Uninstalling widgetsnbextension-3.6.6:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.6\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.7.1\n",
            "    Uninstalling traitlets-5.7.1:\n",
            "      Successfully uninstalled traitlets-5.7.1\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: Pygments\n",
            "    Found existing installation: Pygments 2.16.1\n",
            "    Uninstalling Pygments-2.16.1:\n",
            "      Successfully uninstalled Pygments-2.16.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2023.6.0\n",
            "    Uninstalling fsspec-2023.6.0:\n",
            "      Successfully uninstalled fsspec-2023.6.0\n",
            "  Attempting uninstall: decorator\n",
            "    Found existing installation: decorator 4.4.2\n",
            "    Uninstalling decorator-4.4.2:\n",
            "      Successfully uninstalled decorator-4.4.2\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 2.2.1\n",
            "    Uninstalling cloudpickle-2.2.1:\n",
            "      Successfully uninstalled cloudpickle-2.2.1\n",
            "  Attempting uninstall: blinker\n",
            "    Found existing installation: blinker 1.4\n",
            "\u001b[31mERROR: Cannot uninstall 'blinker'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\u001b[31m\n",
            "\u001b[0mtime: 36 s (started: 2024-03-28 14:01:19 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if RUN_LONG_TESTS:\n",
        "    !python3 AutoML_Zero_Game/alphazero_tutorial.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSkEzCDDbs9A",
        "outputId": "b5043ef3-5f58-4189-db3a-173b70b587ee"
      },
      "id": "ZSkEzCDDbs9A",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 384 µs (started: 2024-03-28 14:01:55 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install bazel"
      ],
      "metadata": {
        "id": "GfsbrCz9c_2-"
      },
      "id": "GfsbrCz9c_2-"
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install g++ unzip zip\n",
        "#!sudo apt-get install default-jdk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4lH1cTTcaxr",
        "outputId": "81d92b3f-5eb0-49bf-bbe8-97a626060495"
      },
      "id": "i4lH1cTTcaxr",
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "g++ is already the newest version (4:11.2.0-1ubuntu1).\n",
            "g++ set to manually installed.\n",
            "zip is already the newest version (3.0-12build2).\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "time: 2.02 s (started: 2024-03-28 14:01:55 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f bazel-*-installer-linux-x86_64.sh*\n",
        "!apt install wget\n",
        "!wget https://github.com/bazelbuild/bazel/releases/download/3.7.2/bazel-3.7.2-installer-linux-x86_64.sh\n",
        "!ls -l bazel-3.7.2-installer-linux-x86_64.sh\n",
        "!chmod +x bazel-3.7.2-installer-linux-x86_64.sh\n",
        "!./bazel-3.7.2-installer-linux-x86_64.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0skFLUWPdE5r",
        "outputId": "221f599d-3d0b-4aef-b07e-766995e37dbf"
      },
      "id": "0skFLUWPdE5r",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "wget is already the newest version (1.21.2-2ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 39 not upgraded.\n",
            "--2024-03-28 14:01:59--  https://github.com/bazelbuild/bazel/releases/download/3.7.2/bazel-3.7.2-installer-linux-x86_64.sh\n",
            "Resolving github.com (github.com)... 140.82.121.4\n",
            "Connecting to github.com (github.com)|140.82.121.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/20773773/07cc4900-4097-11eb-99e3-67aa29fea6e9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240328%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240328T140159Z&X-Amz-Expires=300&X-Amz-Signature=9512153436dd216b653425cdb91b1fa530029e8f6d49fc8dd694b24eff2faeb3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=20773773&response-content-disposition=attachment%3B%20filename%3Dbazel-3.7.2-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-03-28 14:01:59--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/20773773/07cc4900-4097-11eb-99e3-67aa29fea6e9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240328%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240328T140159Z&X-Amz-Expires=300&X-Amz-Signature=9512153436dd216b653425cdb91b1fa530029e8f6d49fc8dd694b24eff2faeb3&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=20773773&response-content-disposition=attachment%3B%20filename%3Dbazel-3.7.2-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44386172 (42M) [application/octet-stream]\n",
            "Saving to: ‘bazel-3.7.2-installer-linux-x86_64.sh’\n",
            "\n",
            "bazel-3.7.2-install 100%[===================>]  42.33M   253MB/s    in 0.2s    \n",
            "\n",
            "2024-03-28 14:01:59 (253 MB/s) - ‘bazel-3.7.2-installer-linux-x86_64.sh’ saved [44386172/44386172]\n",
            "\n",
            "-rw-r--r-- 1 root root 44386172 Dec  7  2021 bazel-3.7.2-installer-linux-x86_64.sh\n",
            "Bazel installer\n",
            "---------------\n",
            "\n",
            "Bazel is bundled with software licensed under the GPLv2 with Classpath exception.\n",
            "You can find the sources next to the installer on our release page:\n",
            "   https://github.com/bazelbuild/bazel/releases\n",
            "\n",
            "# \n",
            "\n",
            "## Build information\n",
            "   - [Commit](https://github.com/bazelbuild/bazel/commit/df2f77c)\n",
            "Uncompressing.......\n",
            "\n",
            "Bazel is now installed!\n",
            "\n",
            "Make sure you have \"/usr/local/bin\" in your path. You can also activate bash\n",
            "completion by adding the following line to your ~/.bashrc:\n",
            "  source /usr/local/lib/bazel/bin/bazel-complete.bash\n",
            "\n",
            "See http://bazel.build/docs/getting-started.html to start a new project!\n",
            "time: 3.24 s (started: 2024-03-28 14:01:57 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check /usr/local/bin is in path\n",
        "!echo $PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG9L9LKqdwjY",
        "outputId": "950d1bea-5f86-4869-f477-2a9f37b9d9e3"
      },
      "id": "KG9L9LKqdwjY",
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n",
            "time: 105 ms (started: 2024-03-28 14:02:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test that the game is working"
      ],
      "metadata": {
        "id": "SvXcno-gdW1l"
      },
      "id": "SvXcno-gdW1l"
    },
    {
      "cell_type": "code",
      "source": [
        "if RUN_LONG_TESTS:\n",
        "    !(cd AutoML_Zero_Game && bash ./run_demo.sh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR-LW3rFb0hL",
        "outputId": "e23978b4-a880-46e1-ae14-b14e75ce43ee"
      },
      "id": "xR-LW3rFb0hL",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 379 µs (started: 2024-03-28 14:02:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if RUN_LONG_TESTS:\n",
        "    !(cd AutoML_Zero_Game && bash ./run_evaluation.sh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIeBEEo9b6we",
        "outputId": "377d2259-8aff-42e2-c04e-ae685a87609c"
      },
      "id": "YIeBEEo9b6we",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 301 µs (started: 2024-03-28 14:02:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the game in interactive mode\n",
        "\n"
      ],
      "metadata": {
        "id": "NJcfANmbk9b4"
      },
      "id": "NJcfANmbk9b4"
    },
    {
      "cell_type": "code",
      "source": [
        "if RUN_INTERACTIVE_TESTS:\n",
        "    !(cd AutoML_Zero_Game && python3 Game.py)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKBjIcFAk-V8",
        "outputId": "913830c6-a461-4e8b-bcc5-619392bce995"
      },
      "id": "ZKBjIcFAk-V8",
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 299 µs (started: 2024-03-28 14:02:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modified *10.Eval.ipynb* code below\n",
        "\n",
        "based on [https://github.com/foersterrobert/AlphaZeroFromScratch/blob/main/10.Eval.ipynb](https://github.com/foersterrobert/AlphaZeroFromScratch/blob/8e8ca01e22c66993dd47941fad58c139fda3c0a9/10.Eval.ipynb)"
      ],
      "metadata": {
        "id": "ADq35AF0xPG0"
      },
      "id": "ADq35AF0xPG0"
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "2d090f5e",
      "metadata": {
        "scrolled": true,
        "id": "2d090f5e",
        "outputId": "d4eac906-d27e-4c40-b646-bcbf04fdeaed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.25.2\n",
            "2.2.1+cu121\n",
            "time: 65.3 ms (started: 2024-03-28 14:02:00 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)\n",
        "\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "from tqdm.notebook import trange\n",
        "\n",
        "import random\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mart&iacute;'s Game"
      ],
      "metadata": {
        "id": "ao5KgjmIvZ7z"
      },
      "id": "ao5KgjmIvZ7z"
    },
    {
      "cell_type": "code",
      "source": [
        "!find . -maxdepth 1 -type d -not -name .\\*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOQKnZ948nkx",
        "outputId": "54f56711-c962-418f-b2ca-f4b1986a72c8"
      },
      "id": "hOQKnZ948nkx",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./AlphaZeroFromScratch\n",
            "./AutoML_Zero_Game\n",
            "./sample_data\n",
            "time: 106 ms (started: 2024-03-28 14:02:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from contextlib import contextmanager\n",
        "\n",
        "# Make relative imports, and, most importantly, Bazel, work\n",
        "GAME_DIR = 'AutoML_Zero_Game'\n",
        "@contextmanager\n",
        "def cd(game_dir: str):\n",
        "    \"\"\"Temporarily change directory to game_dir\"\"\"\n",
        "    original_dir = os.getcwd()  # Save the original working directory\n",
        "    try:\n",
        "        # Change to the desired directory if not already there\n",
        "        if original_dir.split(os.sep)[-1] != game_dir:\n",
        "            new_dir = os.path.join(original_dir, game_dir)\n",
        "            if os.path.isdir(new_dir):\n",
        "                os.chdir(new_dir)\n",
        "                # print(f\"Changed directory to {new_dir}\")\n",
        "            else:\n",
        "                raise RuntimeError(f\"The directory {new_dir} does not exist.\")\n",
        "        yield  # This allows the code within the `with` block to run\n",
        "    finally:\n",
        "        # Change back to the original directory\n",
        "        os.chdir(original_dir)\n",
        "        # print(f\"Reverted to the original directory {original_dir}\")\n",
        "\n",
        "# from Game import Round\n",
        "with cd(GAME_DIR):\n",
        "    from enter_alg import enter_alg\n",
        "    from evaluator import evaluate\n",
        "\n",
        "class Player:\n",
        "    def __init__(self, value):\n",
        "        self.score = 0.0\n",
        "        assert(1 in [value, -value])\n",
        "        self.value = value\n",
        "\n",
        "class MartisGame:\n",
        "    def __init__(self):\n",
        "        self.player1 = Player(1)\n",
        "        self.player2 = Player(-1)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return str(self.__class__.__name__)\n",
        "\n",
        "    def get_initial_state(self):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_next_state(self, state, action, player):\n",
        "        with cd(GAME_DIR):\n",
        "            raise NotImplementedError()\n",
        "\n",
        "    def get_valid_moves(self, state):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def check_win(self, state, action) -> bool:\n",
        "        if action == None:\n",
        "            return False\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_value_and_terminated(self, state, action):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_opponent(self, player: int) -> int:\n",
        "        return -player\n",
        "\n",
        "    def get_opponent_value(self, value: float) -> float:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def change_perspective(self, state, player):\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_encoded_state(self, state):\n",
        "        raise NotImplementedError()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wClOy3Z3vmaL",
        "outputId": "6bc3793b-ce40-4ed9-a5a8-37f3e02a05cf"
      },
      "id": "wClOy3Z3vmaL",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 5.41 ms (started: 2024-03-28 14:02:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tic Tac Toe"
      ],
      "metadata": {
        "id": "z1E7UalFvjjj"
      },
      "id": "z1E7UalFvjjj"
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "a097e1b5",
      "metadata": {
        "id": "a097e1b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03713705-111d-4a82-fc60-ea72e22479f6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.5 ms (started: 2024-03-28 14:02:00 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class TicTacToe:\n",
        "    def __init__(self):\n",
        "        self.row_count = 3\n",
        "        self.column_count = 3\n",
        "        self.action_size = self.row_count * self.column_count\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"TicTacToe\"\n",
        "\n",
        "    def get_initial_state(self):\n",
        "        return np.zeros((self.row_count, self.column_count))\n",
        "\n",
        "    def get_next_state(self, state, action, player):\n",
        "        row = action // self.column_count\n",
        "        column = action % self.column_count\n",
        "        state[row, column] = player\n",
        "        return state\n",
        "\n",
        "    def get_valid_moves(self, state):\n",
        "        return (state.reshape(-1) == 0).astype(np.uint8)\n",
        "\n",
        "    def check_win(self, state, action):\n",
        "        if action == None:\n",
        "            return False\n",
        "\n",
        "        row = action // self.column_count\n",
        "        column = action % self.column_count\n",
        "        player = state[row, column]\n",
        "\n",
        "        return (\n",
        "            np.sum(state[row, :]) == player * self.column_count\n",
        "            or np.sum(state[:, column]) == player * self.row_count\n",
        "            or np.sum(np.diag(state)) == player * self.row_count\n",
        "            or np.sum(np.diag(np.flip(state, axis=0))) == player * self.row_count\n",
        "        )\n",
        "\n",
        "    def get_value_and_terminated(self, state, action):\n",
        "        if self.check_win(state, action):\n",
        "            return 1, True\n",
        "        if np.sum(self.get_valid_moves(state)) == 0:\n",
        "            return 0, True\n",
        "        return 0, False\n",
        "\n",
        "    def get_opponent(self, player):\n",
        "        return -player\n",
        "\n",
        "    def get_opponent_value(self, value):\n",
        "        return -value\n",
        "\n",
        "    def change_perspective(self, state, player):\n",
        "        return state * player\n",
        "\n",
        "    def get_encoded_state(self, state):\n",
        "        encoded_state = np.stack(\n",
        "            (state == -1, state == 0, state == 1)\n",
        "        ).astype(np.float32)\n",
        "\n",
        "        if len(state.shape) == 3:\n",
        "            encoded_state = np.swapaxes(encoded_state, 0, 1)\n",
        "\n",
        "        return encoded_state"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect Four"
      ],
      "metadata": {
        "id": "ZgRPuIpT1GN7"
      },
      "id": "ZgRPuIpT1GN7"
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "682c4ca4",
      "metadata": {
        "id": "682c4ca4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfed518c-33df-4700-e7d6-d7682ed9db86"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.4 ms (started: 2024-03-28 14:02:00 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class ConnectFour:\n",
        "    def __init__(self):\n",
        "        self.row_count = 6\n",
        "        self.column_count = 7\n",
        "        self.action_size = self.column_count\n",
        "        self.in_a_row = 4\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"ConnectFour\"\n",
        "\n",
        "    def get_initial_state(self):\n",
        "        return np.zeros((self.row_count, self.column_count))\n",
        "\n",
        "    def get_next_state(self, state, action, player):\n",
        "        row = np.max(np.where(state[:, action] == 0))\n",
        "        state[row, action] = player\n",
        "        return state\n",
        "\n",
        "    def get_valid_moves(self, state):\n",
        "        return (state[0] == 0).astype(np.uint8)\n",
        "\n",
        "    def check_win(self, state, action):\n",
        "        if action == None:\n",
        "            return False\n",
        "\n",
        "        row = np.min(np.where(state[:, action] != 0))\n",
        "        column = action\n",
        "        player = state[row][column]\n",
        "\n",
        "        def count(offset_row, offset_column):\n",
        "            for i in range(1, self.in_a_row):\n",
        "                r = row + offset_row * i\n",
        "                c = action + offset_column * i\n",
        "                if (\n",
        "                    r < 0\n",
        "                    or r >= self.row_count\n",
        "                    or c < 0\n",
        "                    or c >= self.column_count\n",
        "                    or state[r][c] != player\n",
        "                ):\n",
        "                    return i - 1\n",
        "            return self.in_a_row - 1\n",
        "\n",
        "        return (\n",
        "            count(1, 0) >= self.in_a_row - 1 # vertical\n",
        "            or (count(0, 1) + count(0, -1)) >= self.in_a_row - 1 # horizontal\n",
        "            or (count(1, 1) + count(-1, -1)) >= self.in_a_row - 1 # top left diagonal\n",
        "            or (count(1, -1) + count(-1, 1)) >= self.in_a_row - 1 # top right diagonal\n",
        "        )\n",
        "\n",
        "    def get_value_and_terminated(self, state, action):\n",
        "        if self.check_win(state, action):\n",
        "            return 1, True\n",
        "        if np.sum(self.get_valid_moves(state)) == 0:\n",
        "            return 0, True\n",
        "        return 0, False\n",
        "\n",
        "    def get_opponent(self, player):\n",
        "        return -player\n",
        "\n",
        "    def get_opponent_value(self, value):\n",
        "        return -value\n",
        "\n",
        "    def change_perspective(self, state, player):\n",
        "        return state * player\n",
        "\n",
        "    def get_encoded_state(self, state):\n",
        "        encoded_state = np.stack(\n",
        "            (state == -1, state == 0, state == 1)\n",
        "        ).astype(np.float32)\n",
        "\n",
        "        if len(state.shape) == 3:\n",
        "            encoded_state = np.swapaxes(encoded_state, 0, 1)\n",
        "\n",
        "        return encoded_state"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet"
      ],
      "metadata": {
        "id": "u8LIKCjU1KPw"
      },
      "id": "u8LIKCjU1KPw"
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "02e5b58b",
      "metadata": {
        "id": "02e5b58b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d5f2985-dd9a-4c83-f09b-b0d932cf4093"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.32 ms (started: 2024-03-28 14:02:00 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, game, num_resBlocks, num_hidden, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.startBlock = nn.Sequential(\n",
        "            nn.Conv2d(3, num_hidden, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(num_hidden),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.backBone = nn.ModuleList(\n",
        "            [ResBlock(num_hidden) for i in range(num_resBlocks)]\n",
        "        )\n",
        "\n",
        "        self.policyHead = nn.Sequential(\n",
        "            nn.Conv2d(num_hidden, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * game.row_count * game.column_count, game.action_size)\n",
        "        )\n",
        "\n",
        "        self.valueHead = nn.Sequential(\n",
        "            nn.Conv2d(num_hidden, 3, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(3),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3 * game.row_count * game.column_count, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.startBlock(x)\n",
        "        for resBlock in self.backBone:\n",
        "            x = resBlock(x)\n",
        "        policy = self.policyHead(x)\n",
        "        value = self.valueHead(x)\n",
        "        return policy, value\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, num_hidden):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(num_hidden)\n",
        "        self.conv2 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(num_hidden)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.bn2(self.conv2(x))\n",
        "        x += residual\n",
        "        x = F.relu(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test harness interface is working"
      ],
      "metadata": {
        "id": "vbp7HXWt1TnL"
      },
      "id": "vbp7HXWt1TnL"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "CONFIG[\"TicTacToe\"][\"moves\"] = [\n",
        "    (2, -1),\n",
        "    (4, -1),\n",
        "    (6, 1),\n",
        "    (8, 1),\n",
        "]\n",
        "CONFIG[\"ConnectFour\"][\"moves\"] = [\n",
        "    # columns 0..6\n",
        "    (0, 1),\n",
        "    (0, -1),\n",
        "    (1, 1),\n",
        "    (1, -1),\n",
        "    (2, 1),\n",
        "    (2, -1),\n",
        "    (3, 1),\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "def test_harness(game_name):\n",
        "    game = globals()[game_name]()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    if game_name not in CONFIG:\n",
        "        raise NotImplementedError(f\"Not a known name: {game_name}\")\n",
        "\n",
        "    game_config = CONFIG[game_name]\n",
        "    num_resBlocks = game_config[\"ResNet\"][\"num_resBlocks\"]\n",
        "    num_hidden = game_config[\"ResNet\"][\"num_hidden\"]\n",
        "    model_file_name = game_config[\"model\"]\n",
        "\n",
        "    state = game.get_initial_state()\n",
        "    for move in game_config[\"moves\"]:\n",
        "        position = move[0]\n",
        "        player = move[1]\n",
        "        state = game.get_next_state(state, position, player)\n",
        "\n",
        "    encoded_state = game.get_encoded_state(state)\n",
        "    tensor_state = torch.tensor(encoded_state, device=device).unsqueeze(0)\n",
        "\n",
        "\n",
        "    print(f\"DEBUG: game is {repr(game)}\")\n",
        "    model = ResNet(game, num_resBlocks, num_hidden, device=device)\n",
        "    model.load_state_dict(torch.load(model_file_name, map_location=device))\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    policy, value = model(tensor_state)\n",
        "    value = value.item()\n",
        "    policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n",
        "\n",
        "    print(value)\n",
        "\n",
        "    print(state)\n",
        "    print(tensor_state)\n",
        "\n",
        "    plt.bar(range(game.action_size), policy)\n",
        "    plt.show()\n",
        "\n",
        "for game_name in CONFIG:\n",
        "    print(f\"Testing {game_name}...\")\n",
        "    test_harness(game_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DBWspblt4NnZ",
        "outputId": "ce7d52df-a437-4499-d120-70e1d4a97142"
      },
      "id": "DBWspblt4NnZ",
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing TicTacToe...\n",
            "DEBUG: game is TicTacToe\n",
            "0.9852450489997864\n",
            "[[ 0.  0. -1.]\n",
            " [ 0. -1.  0.]\n",
            " [ 1.  0.  1.]]\n",
            "tensor([[[[0., 0., 1.],\n",
            "          [0., 1., 0.],\n",
            "          [0., 0., 0.]],\n",
            "\n",
            "         [[1., 1., 0.],\n",
            "          [1., 0., 1.],\n",
            "          [0., 1., 0.]],\n",
            "\n",
            "         [[0., 0., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [1., 0., 1.]]]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing ConnectFour...\n",
            "DEBUG: game is ConnectFour\n",
            "0.9972138404846191\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1. -1. -1.  0.  0.  0.  0.]\n",
            " [ 1.  1.  1.  1.  0.  0.  0.]]\n",
            "tensor([[[[0., 0., 0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0., 0., 0.],\n",
            "          [1., 1., 1., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "         [[1., 1., 1., 1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1., 1., 1., 1.],\n",
            "          [0., 0., 0., 1., 1., 1., 1.],\n",
            "          [0., 0., 0., 0., 1., 1., 1.]],\n",
            "\n",
            "         [[0., 0., 0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0., 0., 0.],\n",
            "          [1., 1., 1., 1., 0., 0., 0.]]]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.52 s (started: 2024-03-28 14:02:00 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5J6CzTq-ZvY",
        "outputId": "36a55211-bb5b-4534-df43-32ce1388c315"
      },
      "id": "x5J6CzTq-ZvY",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlphaZeroFromScratch\t\t       model_2.pt\t       optimizer_7_ConnectFour.pt\n",
            "AutoML_Zero_Game\t\t       model_7_ConnectFour.pt  sample_data\n",
            "bazel-3.7.2-installer-linux-x86_64.sh  optimizer_2.pt\n",
            "time: 106 ms (started: 2024-03-28 14:02:02 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Node"
      ],
      "metadata": {
        "id": "h-Fr1Dey1Y6D"
      },
      "id": "h-Fr1Dey1Y6D"
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "21866526",
      "metadata": {
        "id": "21866526",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3b3cfd5-9070-4af1-ad4f-f37216e3ca12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.44 ms (started: 2024-03-28 14:02:02 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class Node:\n",
        "    def __init__(self, game, args, state, parent=None, action_taken=None, prior=0, visit_count=0):\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.state = state\n",
        "        self.parent = parent\n",
        "        self.action_taken = action_taken\n",
        "        self.prior = prior\n",
        "\n",
        "        self.children = []\n",
        "\n",
        "        self.visit_count = visit_count\n",
        "        self.value_sum = 0\n",
        "\n",
        "    def is_fully_expanded(self):\n",
        "        return len(self.children) > 0\n",
        "\n",
        "    def select(self):\n",
        "        best_child = None\n",
        "        best_ucb = -np.inf\n",
        "\n",
        "        for child in self.children:\n",
        "            ucb = self.get_ucb(child)\n",
        "            if ucb > best_ucb:\n",
        "                best_child = child\n",
        "                best_ucb = ucb\n",
        "\n",
        "        return best_child\n",
        "\n",
        "    def get_ucb(self, child):\n",
        "        if child.visit_count == 0:\n",
        "            q_value = 0\n",
        "        else:\n",
        "            q_value = 1 - ((child.value_sum / child.visit_count) + 1) / 2\n",
        "        return q_value + self.args['C'] * (math.sqrt(self.visit_count) / (child.visit_count + 1)) * child.prior\n",
        "\n",
        "    def expand(self, policy):\n",
        "        for action, prob in enumerate(policy):\n",
        "            if prob > 0:\n",
        "                child_state = self.state.copy()\n",
        "                child_state = self.game.get_next_state(child_state, action, 1)\n",
        "                child_state = self.game.change_perspective(child_state, player=-1)\n",
        "\n",
        "                child = Node(self.game, self.args, child_state, self, action, prob)\n",
        "                self.children.append(child)\n",
        "\n",
        "        return child\n",
        "\n",
        "    def backpropagate(self, value):\n",
        "        self.value_sum += value\n",
        "        self.visit_count += 1\n",
        "\n",
        "        value = self.game.get_opponent_value(value)\n",
        "        if self.parent is not None:\n",
        "            self.parent.backpropagate(value)\n",
        "\n",
        "\n",
        "class MCTS:\n",
        "    def __init__(self, game, args, model):\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.model = model\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def search(self, state):\n",
        "        root = Node(self.game, self.args, state, visit_count=1)\n",
        "\n",
        "        policy, _ = self.model(\n",
        "            torch.tensor(self.game.get_encoded_state(state), device=self.model.device).unsqueeze(0)\n",
        "        )\n",
        "        policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n",
        "        policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n",
        "            * np.random.dirichlet([self.args['dirichlet_alpha']] * self.game.action_size)\n",
        "\n",
        "        valid_moves = self.game.get_valid_moves(state)\n",
        "        policy *= valid_moves\n",
        "        policy /= np.sum(policy)\n",
        "        root.expand(policy)\n",
        "\n",
        "        for search in range(self.args['num_searches']):\n",
        "            node = root\n",
        "\n",
        "            while node.is_fully_expanded():\n",
        "                node = node.select()\n",
        "\n",
        "            value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n",
        "            value = self.game.get_opponent_value(value)\n",
        "\n",
        "            if not is_terminal:\n",
        "                policy, value = self.model(\n",
        "                    torch.tensor(self.game.get_encoded_state(node.state), device=self.model.device).unsqueeze(0)\n",
        "                )\n",
        "                policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n",
        "                valid_moves = self.game.get_valid_moves(node.state)\n",
        "                policy *= valid_moves\n",
        "                policy /= np.sum(policy)\n",
        "\n",
        "                value = value.item()\n",
        "\n",
        "                node.expand(policy)\n",
        "\n",
        "            node.backpropagate(value)\n",
        "\n",
        "\n",
        "        action_probs = np.zeros(self.game.action_size)\n",
        "        for child in root.children:\n",
        "            action_probs[child.action_taken] = child.visit_count\n",
        "        action_probs /= np.sum(action_probs)\n",
        "        return action_probs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AlphaZero"
      ],
      "metadata": {
        "id": "-MtBUrqH1eC6"
      },
      "id": "-MtBUrqH1eC6"
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "a3b28ab8",
      "metadata": {
        "id": "a3b28ab8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb564628-9aa8-4dec-c59f-9f339ff17b0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.66 ms (started: 2024-03-28 14:02:02 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class AlphaZero:\n",
        "    def __init__(self, model, optimizer, game, args):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.mcts = MCTS(game, args, model)\n",
        "\n",
        "    def selfPlay(self):\n",
        "        memory = []\n",
        "        player = 1\n",
        "        state = self.game.get_initial_state()\n",
        "\n",
        "        while True:\n",
        "            neutral_state = self.game.change_perspective(state, player)\n",
        "            action_probs = self.mcts.search(neutral_state)\n",
        "\n",
        "            memory.append((neutral_state, action_probs, player))\n",
        "\n",
        "            temperature_action_probs = action_probs ** (1 / self.args['temperature']) # Divide temperature_action_probs with its sum in case of an error\n",
        "            # Normalize temperature_action_probs so that its values sum to 1 by dividing it by its sum:\n",
        "            temperature_action_probs /= np.sum(temperature_action_probs) # Fixes: A ValueError is raised with the message \"probabilities do not sum to 1\".\n",
        "            action = np.random.choice(self.game.action_size, p=temperature_action_probs)\n",
        "\n",
        "            state = self.game.get_next_state(state, action, player)\n",
        "\n",
        "            value, is_terminal = self.game.get_value_and_terminated(state, action)\n",
        "\n",
        "            if is_terminal:\n",
        "                returnMemory = []\n",
        "                for hist_neutral_state, hist_action_probs, hist_player in memory:\n",
        "                    hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n",
        "                    returnMemory.append((\n",
        "                        self.game.get_encoded_state(hist_neutral_state),\n",
        "                        hist_action_probs,\n",
        "                        hist_outcome\n",
        "                    ))\n",
        "                return returnMemory\n",
        "\n",
        "            player = self.game.get_opponent(player)\n",
        "\n",
        "    def train(self, memory):\n",
        "        random.shuffle(memory)\n",
        "        for batchIdx in range(0, len(memory), self.args['batch_size']):\n",
        "            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])] # Change to memory[batchIdx:batchIdx+self.args['batch_size']] in case of an error\n",
        "            state, policy_targets, value_targets = zip(*sample)\n",
        "\n",
        "            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
        "\n",
        "            state = torch.tensor(state, dtype=torch.float32, device=self.model.device)\n",
        "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32, device=self.model.device)\n",
        "            value_targets = torch.tensor(value_targets, dtype=torch.float32, device=self.model.device)\n",
        "\n",
        "            out_policy, out_value = self.model(state)\n",
        "\n",
        "            policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
        "            value_loss = F.mse_loss(out_value, value_targets)\n",
        "            loss = policy_loss + value_loss\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "    def learn(self):\n",
        "        for iteration in range(self.args['num_iterations']):\n",
        "            memory = []\n",
        "\n",
        "            self.model.eval()\n",
        "            for selfPlay_iteration in trange(self.args['num_selfPlay_iterations']):\n",
        "                memory += self.selfPlay()\n",
        "\n",
        "            self.model.train()\n",
        "            for epoch in trange(self.args['num_epochs']):\n",
        "                self.train(memory)\n",
        "\n",
        "            torch.save(self.model.state_dict(), f\"model_{iteration}_{self.game}.pt\")\n",
        "            torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}_{self.game}.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MCTS &mdash; parallel"
      ],
      "metadata": {
        "id": "QVc1-WiS1k_O"
      },
      "id": "QVc1-WiS1k_O"
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "e997f3ea",
      "metadata": {
        "id": "e997f3ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "00be4c10-7db3-40d7-e085-233db7ee4964"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.53 ms (started: 2024-03-28 14:02:02 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class MCTSParallel:\n",
        "    def __init__(self, game, args, model):\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.model = model\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def search(self, states, spGames):\n",
        "        policy, _ = self.model(\n",
        "            torch.tensor(self.game.get_encoded_state(states), device=self.model.device)\n",
        "        )\n",
        "        policy = torch.softmax(policy, axis=1).cpu().numpy()\n",
        "        policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n",
        "            * np.random.dirichlet([self.args['dirichlet_alpha']] * self.game.action_size, size=policy.shape[0])\n",
        "\n",
        "        for i, spg in enumerate(spGames):\n",
        "            spg_policy = policy[i]\n",
        "            valid_moves = self.game.get_valid_moves(states[i])\n",
        "            spg_policy *= valid_moves\n",
        "            spg_policy /= np.sum(spg_policy)\n",
        "\n",
        "            spg.root = Node(self.game, self.args, states[i], visit_count=1)\n",
        "            spg.root.expand(spg_policy)\n",
        "\n",
        "        for search in range(self.args['num_searches']):\n",
        "            for spg in spGames:\n",
        "                spg.node = None\n",
        "                node = spg.root\n",
        "\n",
        "                while node.is_fully_expanded():\n",
        "                    node = node.select()\n",
        "\n",
        "                value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n",
        "                value = self.game.get_opponent_value(value)\n",
        "\n",
        "                if is_terminal:\n",
        "                    node.backpropagate(value)\n",
        "\n",
        "                else:\n",
        "                    spg.node = node\n",
        "\n",
        "            expandable_spGames = [mappingIdx for mappingIdx in range(len(spGames)) if spGames[mappingIdx].node is not None]\n",
        "\n",
        "            if len(expandable_spGames) > 0:\n",
        "                states = np.stack([spGames[mappingIdx].node.state for mappingIdx in expandable_spGames])\n",
        "\n",
        "                policy, value = self.model(\n",
        "                    torch.tensor(self.game.get_encoded_state(states), device=self.model.device)\n",
        "                )\n",
        "                policy = torch.softmax(policy, axis=1).cpu().numpy()\n",
        "                value = value.cpu().numpy()\n",
        "\n",
        "            for i, mappingIdx in enumerate(expandable_spGames):\n",
        "                node = spGames[mappingIdx].node\n",
        "                spg_policy, spg_value = policy[i], value[i]\n",
        "\n",
        "                valid_moves = self.game.get_valid_moves(node.state)\n",
        "                spg_policy *= valid_moves\n",
        "                spg_policy /= np.sum(spg_policy)\n",
        "\n",
        "                node.expand(spg_policy)\n",
        "                node.backpropagate(spg_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AlphaZero &mdash; parallel"
      ],
      "metadata": {
        "id": "CHym_voC1nbG"
      },
      "id": "CHym_voC1nbG"
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "7d0a5a7d",
      "metadata": {
        "id": "7d0a5a7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9c75fb44-e8cb-4dd3-b1f5-4545839db9d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.15 ms (started: 2024-03-28 14:02:02 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class AlphaZeroParallel:\n",
        "    def __init__(self, model, optimizer, game, args):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.mcts = MCTSParallel(game, args, model)\n",
        "\n",
        "    def selfPlay(self):\n",
        "        return_memory = []\n",
        "        player = 1\n",
        "        spGames = [SPG(self.game) for spg in range(self.args['num_parallel_games'])]\n",
        "\n",
        "        while len(spGames) > 0:\n",
        "            states = np.stack([spg.state for spg in spGames])\n",
        "            neutral_states = self.game.change_perspective(states, player)\n",
        "\n",
        "            self.mcts.search(neutral_states, spGames)\n",
        "\n",
        "            for i in range(len(spGames))[::-1]:\n",
        "                spg = spGames[i]\n",
        "\n",
        "                action_probs = np.zeros(self.game.action_size)\n",
        "                for child in spg.root.children:\n",
        "                    action_probs[child.action_taken] = child.visit_count\n",
        "                action_probs /= np.sum(action_probs)\n",
        "\n",
        "                spg.memory.append((spg.root.state, action_probs, player))\n",
        "\n",
        "                temperature_action_probs = action_probs ** (1 / self.args['temperature'])\n",
        "                # Normalize temperature_action_probs so that its values sum to 1 by dividing it by its sum:\n",
        "                temperature_action_probs /= np.sum(temperature_action_probs) # Fixes: A ValueError is raised with the message \"probabilities do not sum to 1\".\n",
        "                action = np.random.choice(self.game.action_size, p=temperature_action_probs) # Divide temperature_action_probs with its sum in case of an error\n",
        "\n",
        "                spg.state = self.game.get_next_state(spg.state, action, player)\n",
        "\n",
        "                value, is_terminal = self.game.get_value_and_terminated(spg.state, action)\n",
        "\n",
        "                if is_terminal:\n",
        "                    for hist_neutral_state, hist_action_probs, hist_player in spg.memory:\n",
        "                        hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n",
        "                        return_memory.append((\n",
        "                            self.game.get_encoded_state(hist_neutral_state),\n",
        "                            hist_action_probs,\n",
        "                            hist_outcome\n",
        "                        ))\n",
        "                    del spGames[i]\n",
        "\n",
        "            player = self.game.get_opponent(player)\n",
        "\n",
        "        return return_memory\n",
        "\n",
        "    def train(self, memory):\n",
        "        random.shuffle(memory)\n",
        "        for batchIdx in range(0, len(memory), self.args['batch_size']):\n",
        "            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])] # Change to memory[batchIdx:batchIdx+self.args['batch_size']] in case of an error\n",
        "            state, policy_targets, value_targets = zip(*sample)\n",
        "\n",
        "            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
        "\n",
        "            state = torch.tensor(state, dtype=torch.float32, device=self.model.device)\n",
        "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32, device=self.model.device)\n",
        "            value_targets = torch.tensor(value_targets, dtype=torch.float32, device=self.model.device)\n",
        "\n",
        "            out_policy, out_value = self.model(state)\n",
        "\n",
        "            policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
        "            value_loss = F.mse_loss(out_value, value_targets)\n",
        "            loss = policy_loss + value_loss\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "    def learn(self):\n",
        "        for iteration in range(self.args['num_iterations']):\n",
        "            memory = []\n",
        "\n",
        "            self.model.eval()\n",
        "            for selfPlay_iteration in trange(self.args['num_selfPlay_iterations'] // self.args['num_parallel_games']):\n",
        "                memory += self.selfPlay()\n",
        "\n",
        "            self.model.train()\n",
        "            for epoch in trange(self.args['num_epochs']):\n",
        "                self.train(memory)\n",
        "\n",
        "            torch.save(self.model.state_dict(), f\"model_{iteration}_{self.game}.pt\")\n",
        "            torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}_{self.game}.pt\")\n",
        "\n",
        "class SPG:\n",
        "    def __init__(self, game):\n",
        "        self.state = game.get_initial_state()\n",
        "        self.memory = []\n",
        "        self.root = None\n",
        "        self.node = None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model\n",
        "\n"
      ],
      "metadata": {
        "id": "RMlEpgYE1t-n"
      },
      "id": "RMlEpgYE1t-n"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltrh --time-style=full-iso > directory_listing.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHKV-VwqS-NW",
        "outputId": "b7a05455-31ce-46e8-b4ef-42bc6567c373"
      },
      "id": "fHKV-VwqS-NW",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 104 ms (started: 2024-03-28 14:02:02 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "24bd91ef",
      "metadata": {
        "id": "24bd91ef",
        "outputId": "a4f5a5f1-04df-4848-b94d-e1c5f2c46834",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 677 µs (started: 2024-03-28 14:02:02 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def train_game(game_name: str):\n",
        "    game = globals()[game_name]()\n",
        "    print(f\"Training {game}...\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    num_resBlocks = CONFIG[CHOOSE_GAME][\"ResNet\"][\"num_resBlocks\"]\n",
        "    num_hidden = CONFIG[CHOOSE_GAME][\"ResNet\"][\"num_hidden\"]\n",
        "\n",
        "    model = ResNet(game, num_resBlocks, num_hidden, device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "\n",
        "    args = {\n",
        "        'C': 2,\n",
        "        'num_searches': 10,\n",
        "        'num_iterations': 1,\n",
        "        'num_selfPlay_iterations': 200,\n",
        "        'num_parallel_games': 100,\n",
        "        'num_epochs': 4,\n",
        "        'batch_size': 128,\n",
        "        'temperature': 1.25,\n",
        "        'dirichlet_epsilon': 0.25,\n",
        "        'dirichlet_alpha': 0.3\n",
        "    }\n",
        "\n",
        "    alphaZero = AlphaZeroParallel(model, optimizer, game, args)\n",
        "    alphaZero.learn()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "already_trained = []\n",
        "\n",
        "if RUN_LONG_TESTS:\n",
        "    # Train the simple games to test the harness\n",
        "    for game_name in CONFIG:\n",
        "        train_game(game_name)\n",
        "        already_trained.append(game_name)\n",
        "\n",
        "# Only train if we haven't already\n",
        "if CHOOSE_GAME not in already_trained:\n",
        "    train_game(CHOOSE_GAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "90a60d45f2534b9fa53dacf9d3ca48ff",
            "7ea7e77a82ad4ea8860b6f507efe3d92",
            "0d18c0a9f3964605914fddb1f8e3f318",
            "81fb4f6d0d154afe863514c9dc4d8f34",
            "a0aa0128c77f401190c48eb59c384f73",
            "ed1aefef2b654e489a2926ca2595bec7",
            "919f381ce8e14fa8930ed68658c5c58b",
            "3ff5bea29eba45219fd98669da289c8f",
            "0801642ef5324f77b69e3b33455375c9",
            "bae7665c362449f3b3543384cdc7a848",
            "283286280f874fc18b8ccf972f245a1d",
            "18148b1c0cfa405ca3e35fbf3094f0ce",
            "40d252a4140b47dcb854a3b4ff0f11f8",
            "9c644dcc08504711a7280e909b7259ec",
            "ada39addfe5d4f60b0a718e8715beed0",
            "e1b1dcb4c07447d187ccda1daeaace85",
            "bf363ffdbb554528838107c76b2538d2",
            "f9afd4ade7d4469ab9a6cfc38b021f23",
            "cf4719bfffc24ab4b090f58299939dc6",
            "d81f3049e2764aa3a8efbe1a2d46e8ed",
            "630207673e6840b997c927373571c96d",
            "44d920aec01240c6b4b6758e3ab22e4b"
          ]
        },
        "id": "Hv5z2QbvU4J0",
        "outputId": "4c6aec29-351d-4529-d3d5-eb5727177985"
      },
      "id": "Hv5z2QbvU4J0",
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training TicTacToe...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "90a60d45f2534b9fa53dacf9d3ca48ff"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "18148b1c0cfa405ca3e35fbf3094f0ce"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 7.73 s (started: 2024-03-28 14:02:02 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltrh --time-style=full-iso | diff directory_listing.txt - | grep -v directory_listing.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNldfA1GoDQ5",
        "outputId": "247172ca-e152-454a-b397-086dbb87ada2"
      },
      "id": "uNldfA1GoDQ5",
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1c1\n",
            "< total 78M\n",
            "---\n",
            "> total 82M\n",
            "10c10,12\n",
            "---\n",
            "> -rw-r--r-- 1 root root 1.3M 2024-03-28 14:02:10.461054481 +0000 model_0_TicTacToe.pt\n",
            "> -rw-r--r-- 1 root root 2.5M 2024-03-28 14:02:10.474055640 +0000 optimizer_0_TicTacToe.pt\n",
            "time: 106 ms (started: 2024-03-28 14:02:10 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rest of the *10.Eval.ipynb* code -- we don't need it right now"
      ],
      "metadata": {
        "id": "kcvRmMw915lz"
      },
      "id": "kcvRmMw915lz"
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "7c470145",
      "metadata": {
        "scrolled": true,
        "id": "7c470145",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de8d43f4-38ad-4b11-91ee-543c9ce0cd8f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 979 µs (started: 2024-03-28 14:02:10 +00:00)\n"
          ]
        }
      ],
      "source": [
        "if False:\n",
        "  game = ConnectFour()\n",
        "  player = 1\n",
        "\n",
        "  args = {\n",
        "      'C': 2,\n",
        "      'num_searches': 10,\n",
        "      'dirichlet_epsilon': 0.,\n",
        "      'dirichlet_alpha': 0.3\n",
        "  }\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  model = ResNet(game, 9, 128, device)\n",
        "  model.load_state_dict(torch.load(\"model_7_ConnectFour.pt\", map_location=device))\n",
        "  model.eval()\n",
        "\n",
        "  mcts = MCTS(game, args, model)\n",
        "\n",
        "  state = game.get_initial_state()\n",
        "\n",
        "\n",
        "  while True:\n",
        "      print(state)\n",
        "\n",
        "      if player == 1:\n",
        "          valid_moves = game.get_valid_moves(state)\n",
        "          print(\"valid_moves\", [i for i in range(game.action_size) if valid_moves[i] == 1])\n",
        "          action = int(input(f\"{player}:\"))\n",
        "\n",
        "          if valid_moves[action] == 0:\n",
        "              print(\"action not valid\")\n",
        "              continue\n",
        "\n",
        "      else:\n",
        "          neutral_state = game.change_perspective(state, player)\n",
        "          mcts_probs = mcts.search(neutral_state)\n",
        "          action = np.argmax(mcts_probs)\n",
        "\n",
        "      state = game.get_next_state(state, action, player)\n",
        "\n",
        "      value, is_terminal = game.get_value_and_terminated(state, action)\n",
        "\n",
        "      if is_terminal:\n",
        "          print(state)\n",
        "          if value == 1:\n",
        "              print(player, \"won\")\n",
        "          else:\n",
        "              print(\"draw\")\n",
        "          break\n",
        "\n",
        "      player = game.get_opponent(player)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "c3528828",
      "metadata": {
        "id": "c3528828",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3326333b-509a-4695-c748-f2f3ef9a6e3b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.96 ms (started: 2024-03-28 14:02:10 +00:00)\n"
          ]
        }
      ],
      "source": [
        "if False:\n",
        "  import kaggle_environments\n",
        "  print(kaggle_environments.__version__)\n",
        "\n",
        "  class KaggleAgent:\n",
        "      def __init__(self, model, game, args):\n",
        "          self.model = model\n",
        "          self.game = game\n",
        "          self.args = args\n",
        "          if self.args['search']:\n",
        "              self.mcts = MCTS(self.game, self.args, self.model)\n",
        "\n",
        "      def run(self, obs, conf):\n",
        "          player = obs['mark'] if obs['mark'] == 1 else -1\n",
        "          state = np.array(obs['board']).reshape(self.game.row_count, self.game.column_count)\n",
        "          state[state==2] = -1\n",
        "\n",
        "          state = self.game.change_perspective(state, player)\n",
        "\n",
        "          if self.args['search']:\n",
        "              policy = self.mcts.search(state)\n",
        "\n",
        "          else:\n",
        "              policy, _ = self.model.predict(state, augment=self.args['augment']) # Not working with the video's implementation\n",
        "\n",
        "          valid_moves = self.game.get_valid_moves(state)\n",
        "          policy *= valid_moves\n",
        "          policy /= np.sum(policy)\n",
        "\n",
        "          if self.args['temperature'] == 0:\n",
        "              action = int(np.argmax(policy))\n",
        "          elif self.args['temperature'] == float('inf'):\n",
        "              action = np.random.choice([r for r in range(self.game.action_size) if policy[r] > 0])\n",
        "          else:\n",
        "              policy = policy ** (1 / self.args['temperature'])\n",
        "              policy /= np.sum(policy)\n",
        "              action = np.random.choice(self.game.action_size, p=policy)\n",
        "\n",
        "          return action\n",
        "\n",
        "  game = TicTacToe()\n",
        "\n",
        "  args = {\n",
        "      'C': 2,\n",
        "      'num_searches': 10,\n",
        "      'dirichlet_epsilon': 0.1,\n",
        "      'dirichlet_alpha': 0.3,\n",
        "      'search': True,\n",
        "      'temperature': 0,\n",
        "  }\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  model = ResNet(game, 4, 64, device)\n",
        "  model.load_state_dict(torch.load(\"model_2.pt\", map_location=device))\n",
        "  model.eval()\n",
        "\n",
        "  env = kaggle_environments.make(\"tictactoe\")\n",
        "\n",
        "  player1 = KaggleAgent(model, game, args)\n",
        "  player2 = KaggleAgent(model, game, args)\n",
        "\n",
        "  players = [player1.run, player2.run]\n",
        "\n",
        "  env.run(players)\n",
        "\n",
        "  env.render(mode=\"ipython\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "myenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "2177f1ca12c1330a133c1d40b46100b268ab447cddcbdfdc0c7b2b7e4840e700"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "h-Fr1Dey1Y6D",
        "-MtBUrqH1eC6",
        "QVc1-WiS1k_O"
      ],
      "toc_visible": true,
      "machine_shape": "hm",
      "gpuType": "V100",
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "90a60d45f2534b9fa53dacf9d3ca48ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_7ea7e77a82ad4ea8860b6f507efe3d92",
              "IPY_MODEL_0d18c0a9f3964605914fddb1f8e3f318",
              "IPY_MODEL_81fb4f6d0d154afe863514c9dc4d8f34"
            ],
            "layout": "IPY_MODEL_a0aa0128c77f401190c48eb59c384f73"
          }
        },
        "7ea7e77a82ad4ea8860b6f507efe3d92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ed1aefef2b654e489a2926ca2595bec7",
            "placeholder": "​",
            "style": "IPY_MODEL_919f381ce8e14fa8930ed68658c5c58b",
            "value": "100%"
          }
        },
        "0d18c0a9f3964605914fddb1f8e3f318": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3ff5bea29eba45219fd98669da289c8f",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0801642ef5324f77b69e3b33455375c9",
            "value": 2
          }
        },
        "81fb4f6d0d154afe863514c9dc4d8f34": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bae7665c362449f3b3543384cdc7a848",
            "placeholder": "​",
            "style": "IPY_MODEL_283286280f874fc18b8ccf972f245a1d",
            "value": " 2/2 [00:04&lt;00:00,  2.14s/it]"
          }
        },
        "a0aa0128c77f401190c48eb59c384f73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ed1aefef2b654e489a2926ca2595bec7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "919f381ce8e14fa8930ed68658c5c58b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3ff5bea29eba45219fd98669da289c8f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0801642ef5324f77b69e3b33455375c9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "bae7665c362449f3b3543384cdc7a848": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "283286280f874fc18b8ccf972f245a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "18148b1c0cfa405ca3e35fbf3094f0ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_40d252a4140b47dcb854a3b4ff0f11f8",
              "IPY_MODEL_9c644dcc08504711a7280e909b7259ec",
              "IPY_MODEL_ada39addfe5d4f60b0a718e8715beed0"
            ],
            "layout": "IPY_MODEL_e1b1dcb4c07447d187ccda1daeaace85"
          }
        },
        "40d252a4140b47dcb854a3b4ff0f11f8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bf363ffdbb554528838107c76b2538d2",
            "placeholder": "​",
            "style": "IPY_MODEL_f9afd4ade7d4469ab9a6cfc38b021f23",
            "value": "100%"
          }
        },
        "9c644dcc08504711a7280e909b7259ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cf4719bfffc24ab4b090f58299939dc6",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d81f3049e2764aa3a8efbe1a2d46e8ed",
            "value": 4
          }
        },
        "ada39addfe5d4f60b0a718e8715beed0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_630207673e6840b997c927373571c96d",
            "placeholder": "​",
            "style": "IPY_MODEL_44d920aec01240c6b4b6758e3ab22e4b",
            "value": " 4/4 [00:01&lt;00:00,  4.93it/s]"
          }
        },
        "e1b1dcb4c07447d187ccda1daeaace85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bf363ffdbb554528838107c76b2538d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f9afd4ade7d4469ab9a6cfc38b021f23": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cf4719bfffc24ab4b090f58299939dc6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d81f3049e2764aa3a8efbe1a2d46e8ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "630207673e6840b997c927373571c96d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "44d920aec01240c6b4b6758e3ab22e4b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
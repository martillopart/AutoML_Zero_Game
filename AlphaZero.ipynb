{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/martillopart/AutoML_Zero_Game/blob/main/AlphaZero.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Configuration"
      ],
      "metadata": {
        "id": "lg0NcA-SeeA8"
      },
      "id": "lg0NcA-SeeA8"
    },
    {
      "cell_type": "code",
      "source": [
        "CHOOSE_GAME = \"ConnectFour\" # @param [\"ConnectFour\", \"TicTacToe\", \"MartisGame\"]\n",
        "\n",
        "# @markdown Enable long & interactive tests if you want to thoroughly test the notebook; during normal development, you would typically run them once in a while to make sure everything still works.\n",
        "RUN_LONG_TESTS = False # @param {type:\"boolean\"}\n",
        "RUN_INTERACTIVE_TESTS = False # @param {type:\"boolean\"}"
      ],
      "metadata": {
        "cellView": "form",
        "id": "kg1qsIq-edPl"
      },
      "id": "kg1qsIq-edPl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\n",
        "    \"TicTacToe\": {\n",
        "        \"model\": \"model_2.pt\",\n",
        "        \"ResNet\": {\n",
        "            \"num_resBlocks\": 4,\n",
        "            \"num_hidden\": 64,\n",
        "        }\n",
        "    },\n",
        "    \"ConnectFour\": {\n",
        "        \"model\": \"model_7_ConnectFour.pt\",\n",
        "        \"ResNet\": {\n",
        "            \"num_resBlocks\": 9,\n",
        "            \"num_hidden\": 128,\n",
        "        },\n",
        "    },\n",
        "}\n",
        "\n",
        "assert CHOOSE_GAME in CONFIG"
      ],
      "metadata": {
        "id": "E227f7sTMQGU"
      },
      "id": "E227f7sTMQGU",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# print cell execution time for every cell\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "skOntXD6iIh8",
        "outputId": "7d87d365-a93a-41eb-ae7e-80ac33dd0a77"
      },
      "id": "skOntXD6iIh8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.2-py2.py3-none-any.whl (7.0 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.10/dist-packages (from ipython-autotime) (7.34.0)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (67.7.2)\n",
            "Collecting jedi>=0.16 (from ipython->ipython-autotime)\n",
            "  Downloading jedi-0.19.1-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: decorator in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (3.0.43)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (2.16.1)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: matplotlib-inline in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (0.1.6)\n",
            "Requirement already satisfied: pexpect>4.3 in /usr/local/lib/python3.10/dist-packages (from ipython->ipython-autotime) (4.9.0)\n",
            "Requirement already satisfied: parso<0.9.0,>=0.8.3 in /usr/local/lib/python3.10/dist-packages (from jedi>=0.16->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.10/dist-packages (from pexpect>4.3->ipython->ipython-autotime) (0.7.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.10/dist-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.13)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.2 jedi-0.19.1\n",
            "time: 256 µs (started: 2024-04-05 13:51:19 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Notarize environmental properties"
      ],
      "metadata": {
        "id": "e30XDYNAdAuI"
      },
      "id": "e30XDYNAdAuI"
    },
    {
      "cell_type": "code",
      "source": [
        "!python --version\n",
        "\n",
        "!pip install torch\n",
        "!pip install psutil\n",
        "\n",
        "import torch\n",
        "import psutil\n",
        "\n",
        "# Function to convert bytes to GB\n",
        "def bytes_to_gb(bytes_value):\n",
        "    return round(bytes_value / (1024**3), 2)\n",
        "\n",
        "# Check if GPU is available\n",
        "if torch.cuda.is_available():\n",
        "    # Get the name of the GPU device\n",
        "    device_name = torch.cuda.get_device_name(0)\n",
        "    print(\"GPU Make and Model: \", device_name)\n",
        "\n",
        "    # Get the GPU VRAM amount\n",
        "    gpu_vram = torch.cuda.get_device_properties(0).total_memory\n",
        "    print(\"GPU VRAM Amount: {} GB\".format(bytes_to_gb(gpu_vram)))\n",
        "else:\n",
        "    print(\"No GPU detected.\")\n",
        "\n",
        "# Get the CPU RAM amount\n",
        "cpu_ram = psutil.virtual_memory().total\n",
        "print(\"CPU RAM Amount: {} GB\".format(bytes_to_gb(cpu_ram)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FURBql5f0z1-",
        "outputId": "85792070-4d7c-4f0d-989d-f9b32a7e325d"
      },
      "id": "FURBql5f0z1-",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python 3.10.12\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (2.2.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch) (3.13.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch) (4.10.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch) (3.1.3)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch) (2023.6.0)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (23.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.7/23.7 MB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-runtime-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (823 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m823.6/823.6 kB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cuda-cupti-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (14.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m86.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cudnn-cu12==8.9.2.26 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-8.9.2.26-py3-none-manylinux1_x86_64.whl (731.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m731.7/731.7 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cublas-cu12==12.1.3.1 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.1.3.1-py3-none-manylinux1_x86_64.whl (410.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m410.6/410.6 MB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cufft-cu12==11.0.2.54 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.0.2.54-py3-none-manylinux1_x86_64.whl (121.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.6/121.6 MB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-curand-cu12==10.3.2.106 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.2.106-py3-none-manylinux1_x86_64.whl (56.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusolver-cu12==11.4.5.107 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.4.5.107-py3-none-manylinux1_x86_64.whl (124.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.2/124.2 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-cusparse-cu12==12.1.0.106 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.1.0.106-py3-none-manylinux1_x86_64.whl (196.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m196.0/196.0 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nccl-cu12==2.19.3 (from torch)\n",
            "  Downloading nvidia_nccl_cu12-2.19.3-py3-none-manylinux1_x86_64.whl (166.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 MB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting nvidia-nvtx-cu12==12.1.105 (from torch)\n",
            "  Downloading nvidia_nvtx_cu12-12.1.105-py3-none-manylinux1_x86_64.whl (99 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m13.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch) (2.2.0)\n",
            "Collecting nvidia-nvjitlink-cu12 (from nvidia-cusolver-cu12==11.4.5.107->torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m76.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch) (1.3.0)\n",
            "Installing collected packages: nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "Successfully installed nvidia-cublas-cu12-12.1.3.1 nvidia-cuda-cupti-cu12-12.1.105 nvidia-cuda-nvrtc-cu12-12.1.105 nvidia-cuda-runtime-cu12-12.1.105 nvidia-cudnn-cu12-8.9.2.26 nvidia-cufft-cu12-11.0.2.54 nvidia-curand-cu12-10.3.2.106 nvidia-cusolver-cu12-11.4.5.107 nvidia-cusparse-cu12-12.1.0.106 nvidia-nccl-cu12-2.19.3 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.1.105\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (5.9.5)\n",
            "GPU Make and Model:  Tesla V100-SXM2-16GB\n",
            "GPU VRAM Amount: 15.77 GB\n",
            "CPU RAM Amount: 50.99 GB\n",
            "time: 1min 11s (started: 2024-04-05 13:51:19 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download the git repos and install dependencies"
      ],
      "metadata": {
        "id": "pWtaG7Q1xW5T"
      },
      "id": "pWtaG7Q1xW5T"
    },
    {
      "cell_type": "code",
      "source": [
        "! git clone https://github.com/foersterrobert/AlphaZeroFromScratch\n",
        "! cp AlphaZeroFromScratch/*.pt .\n",
        "\n",
        "! git clone https://github.com/martillopart/AutoML_Zero_Game\n",
        "\n",
        "# XXX ERROR: Cannot uninstall 'blinker'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\n",
        "! pip install -r AutoML_Zero_Game/requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuoDlbdYxM4I",
        "outputId": "0a0d2d3e-5510-442d-9053-326f9668d860"
      },
      "id": "tuoDlbdYxM4I",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'AlphaZeroFromScratch'...\n",
            "remote: Enumerating objects: 39, done.\u001b[K\n",
            "remote: Counting objects: 100% (24/24), done.\u001b[K\n",
            "remote: Compressing objects: 100% (11/11), done.\u001b[K\n",
            "remote: Total 39 (delta 20), reused 13 (delta 13), pack-reused 15\u001b[K\n",
            "Receiving objects: 100% (39/39), 32.05 MiB | 22.62 MiB/s, done.\n",
            "Resolving deltas: 100% (23/23), done.\n",
            "Cloning into 'AutoML_Zero_Game'...\n",
            "remote: Enumerating objects: 133, done.\u001b[K\n",
            "remote: Counting objects: 100% (133/133), done.\u001b[K\n",
            "remote: Compressing objects: 100% (110/110), done.\u001b[K\n",
            "remote: Total 133 (delta 27), reused 119 (delta 20), pack-reused 0\u001b[K\n",
            "Receiving objects: 100% (133/133), 32.51 MiB | 20.71 MiB/s, done.\n",
            "Resolving deltas: 100% (27/27), done.\n",
            "Collecting asttokens==2.4.1 (from -r AutoML_Zero_Game/requirements.txt (line 1))\n",
            "  Downloading asttokens-2.4.1-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: attrs==23.2.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 2)) (23.2.0)\n",
            "Collecting blinker==1.7.0 (from -r AutoML_Zero_Game/requirements.txt (line 3))\n",
            "  Downloading blinker-1.7.0-py3-none-any.whl (13 kB)\n",
            "Requirement already satisfied: certifi==2024.2.2 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 4)) (2024.2.2)\n",
            "Requirement already satisfied: charset-normalizer==3.3.2 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 5)) (3.3.2)\n",
            "Requirement already satisfied: click==8.1.7 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 6)) (8.1.7)\n",
            "Collecting cloudpickle==3.0.0 (from -r AutoML_Zero_Game/requirements.txt (line 7))\n",
            "  Downloading cloudpickle-3.0.0-py3-none-any.whl (20 kB)\n",
            "Collecting comm==0.2.2 (from -r AutoML_Zero_Game/requirements.txt (line 8))\n",
            "  Downloading comm-0.2.2-py3-none-any.whl (7.2 kB)\n",
            "Requirement already satisfied: contourpy==1.2.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 9)) (1.2.0)\n",
            "Requirement already satisfied: cycler==0.12.1 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 10)) (0.12.1)\n",
            "Collecting decorator==5.1.1 (from -r AutoML_Zero_Game/requirements.txt (line 11))\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Requirement already satisfied: exceptiongroup==1.2.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 12)) (1.2.0)\n",
            "Collecting executing==2.0.1 (from -r AutoML_Zero_Game/requirements.txt (line 13))\n",
            "  Downloading executing-2.0.1-py2.py3-none-any.whl (24 kB)\n",
            "Collecting Farama-Notifications==0.0.4 (from -r AutoML_Zero_Game/requirements.txt (line 14))\n",
            "  Downloading Farama_Notifications-0.0.4-py3-none-any.whl (2.5 kB)\n",
            "Requirement already satisfied: filelock==3.13.3 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 15)) (3.13.3)\n",
            "Collecting Flask==3.0.2 (from -r AutoML_Zero_Game/requirements.txt (line 16))\n",
            "  Downloading flask-3.0.2-py3-none-any.whl (101 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.3/101.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fonttools==4.50.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 17)) (4.50.0)\n",
            "Collecting fsspec==2024.3.1 (from -r AutoML_Zero_Game/requirements.txt (line 18))\n",
            "  Downloading fsspec-2024.3.1-py3-none-any.whl (171 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m172.0/172.0 kB\u001b[0m \u001b[31m10.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting gymnasium==0.29.0 (from -r AutoML_Zero_Game/requirements.txt (line 19))\n",
            "  Downloading gymnasium-0.29.0-py3-none-any.whl (953 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m953.8/953.8 kB\u001b[0m \u001b[31m31.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub==0.22.1 (from -r AutoML_Zero_Game/requirements.txt (line 20))\n",
            "  Downloading huggingface_hub-0.22.1-py3-none-any.whl (388 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m388.6/388.6 kB\u001b[0m \u001b[31m40.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna==3.6 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 21)) (3.6)\n",
            "Collecting ipython==8.22.2 (from -r AutoML_Zero_Game/requirements.txt (line 22))\n",
            "  Downloading ipython-8.22.2-py3-none-any.whl (811 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m812.0/812.0 kB\u001b[0m \u001b[31m63.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ipywidgets==8.1.2 (from -r AutoML_Zero_Game/requirements.txt (line 23))\n",
            "  Downloading ipywidgets-8.1.2-py3-none-any.whl (139 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.4/139.4 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: itsdangerous==2.1.2 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 24)) (2.1.2)\n",
            "Requirement already satisfied: jedi==0.19.1 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 25)) (0.19.1)\n",
            "Requirement already satisfied: Jinja2==3.1.3 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 26)) (3.1.3)\n",
            "Collecting jsonschema==4.21.1 (from -r AutoML_Zero_Game/requirements.txt (line 27))\n",
            "  Downloading jsonschema-4.21.1-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.5/85.5 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: jsonschema-specifications==2023.12.1 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 28)) (2023.12.1)\n",
            "Requirement already satisfied: jupyterlab_widgets==3.0.10 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 29)) (3.0.10)\n",
            "Collecting kaggle-environments==1.14.3 (from -r AutoML_Zero_Game/requirements.txt (line 30))\n",
            "  Downloading kaggle_environments-1.14.3-py2.py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: kiwisolver==1.4.5 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 31)) (1.4.5)\n",
            "Requirement already satisfied: MarkupSafe==2.1.5 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 32)) (2.1.5)\n",
            "Collecting matplotlib==3.8.3 (from -r AutoML_Zero_Game/requirements.txt (line 33))\n",
            "  Downloading matplotlib-3.8.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: matplotlib-inline==0.1.6 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 34)) (0.1.6)\n",
            "Requirement already satisfied: mpmath==1.3.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 35)) (1.3.0)\n",
            "Requirement already satisfied: networkx==3.2.1 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 36)) (3.2.1)\n",
            "Collecting numpy==1.26.4 (from -r AutoML_Zero_Game/requirements.txt (line 37))\n",
            "  Downloading numpy-1.26.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m69.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 38)) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 39)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 40)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 41)) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 42)) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 43)) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 44)) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 45)) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 46)) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 47)) (2.19.3)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.99 (from -r AutoML_Zero_Game/requirements.txt (line 48))\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.99-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 49)) (12.1.105)\n",
            "Requirement already satisfied: packaging==24.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 50)) (24.0)\n",
            "Collecting pandas==2.2.1 (from -r AutoML_Zero_Game/requirements.txt (line 51))\n",
            "  Downloading pandas-2.2.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: parso==0.8.3 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 52)) (0.8.3)\n",
            "Collecting pettingzoo==1.24.0 (from -r AutoML_Zero_Game/requirements.txt (line 53))\n",
            "  Downloading pettingzoo-1.24.0-py3-none-any.whl (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.2/840.2 kB\u001b[0m \u001b[31m59.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pexpect==4.9.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 54)) (4.9.0)\n",
            "Collecting pillow==10.2.0 (from -r AutoML_Zero_Game/requirements.txt (line 55))\n",
            "  Downloading pillow-10.2.0-cp310-cp310-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m104.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: prompt-toolkit==3.0.43 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 56)) (3.0.43)\n",
            "Requirement already satisfied: ptyprocess==0.7.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 57)) (0.7.0)\n",
            "Collecting pure-eval==0.2.2 (from -r AutoML_Zero_Game/requirements.txt (line 58))\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting Pygments==2.17.2 (from -r AutoML_Zero_Game/requirements.txt (line 59))\n",
            "  Downloading pygments-2.17.2-py3-none-any.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m76.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyparsing==3.1.2 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 60)) (3.1.2)\n",
            "Collecting python-dateutil==2.9.0.post0 (from -r AutoML_Zero_Game/requirements.txt (line 61))\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pytz==2024.1 (from -r AutoML_Zero_Game/requirements.txt (line 62))\n",
            "  Downloading pytz-2024.1-py2.py3-none-any.whl (505 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m505.5/505.5 kB\u001b[0m \u001b[31m51.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML==6.0.1 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 63)) (6.0.1)\n",
            "Requirement already satisfied: referencing==0.34.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 64)) (0.34.0)\n",
            "Requirement already satisfied: regex==2023.12.25 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 65)) (2023.12.25)\n",
            "Requirement already satisfied: requests==2.31.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 66)) (2.31.0)\n",
            "Requirement already satisfied: rpds-py==0.18.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 67)) (0.18.0)\n",
            "Requirement already satisfied: safetensors==0.4.2 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 68)) (0.4.2)\n",
            "Collecting scipy==1.12.0 (from -r AutoML_Zero_Game/requirements.txt (line 69))\n",
            "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Shimmy==1.3.0 (from -r AutoML_Zero_Game/requirements.txt (line 70))\n",
            "  Downloading Shimmy-1.3.0-py3-none-any.whl (37 kB)\n",
            "Requirement already satisfied: six==1.16.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 71)) (1.16.0)\n",
            "Collecting stable-baselines3==2.1.0 (from -r AutoML_Zero_Game/requirements.txt (line 72))\n",
            "  Downloading stable_baselines3-2.1.0-py3-none-any.whl (178 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m178.7/178.7 kB\u001b[0m \u001b[31m21.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stack-data==0.6.3 (from -r AutoML_Zero_Game/requirements.txt (line 73))\n",
            "  Downloading stack_data-0.6.3-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: sympy==1.12 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 74)) (1.12)\n",
            "Requirement already satisfied: tokenizers==0.15.2 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 75)) (0.15.2)\n",
            "Requirement already satisfied: torch==2.2.1 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 76)) (2.2.1+cu121)\n",
            "Requirement already satisfied: tqdm==4.66.2 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 77)) (4.66.2)\n",
            "Collecting traitlets==5.14.2 (from -r AutoML_Zero_Game/requirements.txt (line 78))\n",
            "  Downloading traitlets-5.14.2-py3-none-any.whl (85 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m85.4/85.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting transformers==4.39.1 (from -r AutoML_Zero_Game/requirements.txt (line 79))\n",
            "  Downloading transformers-4.39.1-py3-none-any.whl (8.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.8/8.8 MB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 80)) (2.2.0)\n",
            "Requirement already satisfied: typing_extensions==4.10.0 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 81)) (4.10.0)\n",
            "Requirement already satisfied: tzdata==2024.1 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 82)) (2024.1)\n",
            "Collecting urllib3==2.2.1 (from -r AutoML_Zero_Game/requirements.txt (line 83))\n",
            "  Downloading urllib3-2.2.1-py3-none-any.whl (121 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m121.1/121.1 kB\u001b[0m \u001b[31m17.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting vec-noise==1.1.4 (from -r AutoML_Zero_Game/requirements.txt (line 84))\n",
            "  Downloading vec_noise-1.1.4.zip (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.1/134.1 kB\u001b[0m \u001b[31m19.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: wcwidth==0.2.13 in /usr/local/lib/python3.10/dist-packages (from -r AutoML_Zero_Game/requirements.txt (line 85)) (0.2.13)\n",
            "Collecting Werkzeug==3.0.1 (from -r AutoML_Zero_Game/requirements.txt (line 86))\n",
            "  Downloading werkzeug-3.0.1-py3-none-any.whl (226 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.7/226.7 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting widgetsnbextension==4.0.10 (from -r AutoML_Zero_Game/requirements.txt (line 87))\n",
            "  Downloading widgetsnbextension-4.0.10-py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m104.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: vec-noise\n",
            "  Building wheel for vec-noise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for vec-noise: filename=vec_noise-1.1.4-cp310-cp310-linux_x86_64.whl size=73652 sha256=785b2f5d6d8a09a25881eccd4de5aa0d29154765d1215ac63901aca2ccad929e\n",
            "  Stored in directory: /root/.cache/pip/wheels/2b/28/e4/f710af1a5bb24bb6da3d4f65081e268ca85034b7ac0a9237fe\n",
            "Successfully built vec-noise\n",
            "Installing collected packages: pytz, pure-eval, Farama-Notifications, widgetsnbextension, Werkzeug, urllib3, traitlets, python-dateutil, Pygments, pillow, nvidia-nvjitlink-cu12, numpy, fsspec, executing, decorator, cloudpickle, blinker, asttokens, vec-noise, stack-data, scipy, pandas, gymnasium, Flask, comm, Shimmy, pettingzoo, matplotlib, jsonschema, ipython, huggingface-hub, ipywidgets, transformers, stable-baselines3, kaggle-environments\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2023.4\n",
            "    Uninstalling pytz-2023.4:\n",
            "      Successfully uninstalled pytz-2023.4\n",
            "  Attempting uninstall: widgetsnbextension\n",
            "    Found existing installation: widgetsnbextension 3.6.6\n",
            "    Uninstalling widgetsnbextension-3.6.6:\n",
            "      Successfully uninstalled widgetsnbextension-3.6.6\n",
            "  Attempting uninstall: Werkzeug\n",
            "    Found existing installation: Werkzeug 3.0.2\n",
            "    Uninstalling Werkzeug-3.0.2:\n",
            "      Successfully uninstalled Werkzeug-3.0.2\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.0.7\n",
            "    Uninstalling urllib3-2.0.7:\n",
            "      Successfully uninstalled urllib3-2.0.7\n",
            "  Attempting uninstall: traitlets\n",
            "    Found existing installation: traitlets 5.7.1\n",
            "    Uninstalling traitlets-5.7.1:\n",
            "      Successfully uninstalled traitlets-5.7.1\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: Pygments\n",
            "    Found existing installation: Pygments 2.16.1\n",
            "    Uninstalling Pygments-2.16.1:\n",
            "      Successfully uninstalled Pygments-2.16.1\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: Pillow 9.4.0\n",
            "    Uninstalling Pillow-9.4.0:\n",
            "      Successfully uninstalled Pillow-9.4.0\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.4.127\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.25.2\n",
            "    Uninstalling numpy-1.25.2:\n",
            "      Successfully uninstalled numpy-1.25.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2023.6.0\n",
            "    Uninstalling fsspec-2023.6.0:\n",
            "      Successfully uninstalled fsspec-2023.6.0\n",
            "  Attempting uninstall: decorator\n",
            "    Found existing installation: decorator 4.4.2\n",
            "    Uninstalling decorator-4.4.2:\n",
            "      Successfully uninstalled decorator-4.4.2\n",
            "  Attempting uninstall: cloudpickle\n",
            "    Found existing installation: cloudpickle 2.2.1\n",
            "    Uninstalling cloudpickle-2.2.1:\n",
            "      Successfully uninstalled cloudpickle-2.2.1\n",
            "  Attempting uninstall: blinker\n",
            "    Found existing installation: blinker 1.4\n",
            "\u001b[31mERROR: Cannot uninstall 'blinker'. It is a distutils installed project and thus we cannot accurately determine which files belong to it which would lead to only a partial uninstall.\u001b[0m\u001b[31m\n",
            "\u001b[0mtime: 48 s (started: 2024-04-05 13:52:31 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if RUN_LONG_TESTS:\n",
        "    !python3 AutoML_Zero_Game/alphazero_tutorial.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZSkEzCDDbs9A",
        "outputId": "10283fc6-0a13-49b6-8eb3-dc71861e22df"
      },
      "id": "ZSkEzCDDbs9A",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 482 µs (started: 2024-04-05 13:53:19 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Install bazel"
      ],
      "metadata": {
        "id": "GfsbrCz9c_2-"
      },
      "id": "GfsbrCz9c_2-"
    },
    {
      "cell_type": "code",
      "source": [
        "!apt install g++ unzip zip\n",
        "#!sudo apt-get install default-jdk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i4lH1cTTcaxr",
        "outputId": "2be4ca7f-6b1a-4444-b202-fd0c575c2a41"
      },
      "id": "i4lH1cTTcaxr",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "g++ is already the newest version (4:11.2.0-1ubuntu1).\n",
            "g++ set to manually installed.\n",
            "zip is already the newest version (3.0-12build2).\n",
            "unzip is already the newest version (6.0-26ubuntu3.2).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "time: 2.12 s (started: 2024-04-05 13:53:19 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f bazel-*-installer-linux-x86_64.sh*\n",
        "!apt install wget\n",
        "!wget https://github.com/bazelbuild/bazel/releases/download/3.7.2/bazel-3.7.2-installer-linux-x86_64.sh\n",
        "!ls -l bazel-3.7.2-installer-linux-x86_64.sh\n",
        "!chmod +x bazel-3.7.2-installer-linux-x86_64.sh\n",
        "!./bazel-3.7.2-installer-linux-x86_64.sh"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0skFLUWPdE5r",
        "outputId": "f9cf1447-88de-4612-a121-596caf1c0584"
      },
      "id": "0skFLUWPdE5r",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "wget is already the newest version (1.21.2-2ubuntu1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 45 not upgraded.\n",
            "--2024-04-05 13:53:23--  https://github.com/bazelbuild/bazel/releases/download/3.7.2/bazel-3.7.2-installer-linux-x86_64.sh\n",
            "Resolving github.com (github.com)... 20.27.177.113\n",
            "Connecting to github.com (github.com)|20.27.177.113|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/20773773/07cc4900-4097-11eb-99e3-67aa29fea6e9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240405%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240405T135323Z&X-Amz-Expires=300&X-Amz-Signature=5cee61a6f25629a64b378e10f334cd913aab1baa3f52874b48cf6d54896ae0ab&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=20773773&response-content-disposition=attachment%3B%20filename%3Dbazel-3.7.2-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-04-05 13:53:23--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/20773773/07cc4900-4097-11eb-99e3-67aa29fea6e9?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240405%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240405T135323Z&X-Amz-Expires=300&X-Amz-Signature=5cee61a6f25629a64b378e10f334cd913aab1baa3f52874b48cf6d54896ae0ab&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=20773773&response-content-disposition=attachment%3B%20filename%3Dbazel-3.7.2-installer-linux-x86_64.sh&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.110.133, 185.199.109.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44386172 (42M) [application/octet-stream]\n",
            "Saving to: ‘bazel-3.7.2-installer-linux-x86_64.sh’\n",
            "\n",
            "bazel-3.7.2-install 100%[===================>]  42.33M  28.8MB/s    in 1.5s    \n",
            "\n",
            "2024-04-05 13:53:26 (28.8 MB/s) - ‘bazel-3.7.2-installer-linux-x86_64.sh’ saved [44386172/44386172]\n",
            "\n",
            "-rw-r--r-- 1 root root 44386172 Dec  7  2021 bazel-3.7.2-installer-linux-x86_64.sh\n",
            "Bazel installer\n",
            "---------------\n",
            "\n",
            "Bazel is bundled with software licensed under the GPLv2 with Classpath exception.\n",
            "You can find the sources next to the installer on our release page:\n",
            "   https://github.com/bazelbuild/bazel/releases\n",
            "\n",
            "# \n",
            "\n",
            "## Build information\n",
            "   - [Commit](https://github.com/bazelbuild/bazel/commit/df2f77c)\n",
            "Uncompressing.......\n",
            "\n",
            "Bazel is now installed!\n",
            "\n",
            "Make sure you have \"/usr/local/bin\" in your path. You can also activate bash\n",
            "completion by adding the following line to your ~/.bashrc:\n",
            "  source /usr/local/lib/bazel/bin/bazel-complete.bash\n",
            "\n",
            "See http://bazel.build/docs/getting-started.html to start a new project!\n",
            "time: 5.35 s (started: 2024-04-05 13:53:21 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check /usr/local/bin is in path\n",
        "!echo $PATH"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KG9L9LKqdwjY",
        "outputId": "3f225f96-fa1a-4000-d20c-aa2566fe54f8"
      },
      "id": "KG9L9LKqdwjY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/opt/bin:/usr/local/nvidia/bin:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/tools/node/bin:/tools/google-cloud-sdk/bin\n",
            "time: 104 ms (started: 2024-04-05 13:53:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test that the game is working"
      ],
      "metadata": {
        "id": "SvXcno-gdW1l"
      },
      "id": "SvXcno-gdW1l"
    },
    {
      "cell_type": "code",
      "source": [
        "if RUN_LONG_TESTS:\n",
        "    !(cd AutoML_Zero_Game && bash ./run_demo.sh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR-LW3rFb0hL",
        "outputId": "21ff8f3a-de30-42cc-abe9-8ba33d07fb5e"
      },
      "id": "xR-LW3rFb0hL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 372 µs (started: 2024-04-05 13:53:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "if RUN_LONG_TESTS:\n",
        "    !(cd AutoML_Zero_Game && bash ./run_evaluation.sh)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIeBEEo9b6we",
        "outputId": "e617c221-564a-4167-83f9-c68cf764c16d"
      },
      "id": "YIeBEEo9b6we",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 287 µs (started: 2024-04-05 13:53:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Run the game in interactive mode\n",
        "\n"
      ],
      "metadata": {
        "id": "NJcfANmbk9b4"
      },
      "id": "NJcfANmbk9b4"
    },
    {
      "cell_type": "code",
      "source": [
        "if RUN_INTERACTIVE_TESTS:\n",
        "    !(cd AutoML_Zero_Game && python3 Game.py)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZKBjIcFAk-V8",
        "outputId": "63bd891f-a2eb-448a-9b9a-822a53952089"
      },
      "id": "ZKBjIcFAk-V8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 381 µs (started: 2024-04-05 13:53:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Modified *10.Eval.ipynb* code below\n",
        "\n",
        "based on [https://github.com/foersterrobert/AlphaZeroFromScratch/blob/main/10.Eval.ipynb](https://github.com/foersterrobert/AlphaZeroFromScratch/blob/8e8ca01e22c66993dd47941fad58c139fda3c0a9/10.Eval.ipynb)"
      ],
      "metadata": {
        "id": "ADq35AF0xPG0"
      },
      "id": "ADq35AF0xPG0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2d090f5e",
      "metadata": {
        "scrolled": true,
        "id": "2d090f5e",
        "outputId": "d183e28a-10ce-47bf-e0ae-863b0c5b7c76",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.25.2\n",
            "2.2.1+cu121\n",
            "time: 61.9 ms (started: 2024-04-05 13:53:26 +00:00)\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "print(np.__version__)\n",
        "\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "torch.manual_seed(0)\n",
        "\n",
        "from tqdm.notebook import trange\n",
        "\n",
        "import random\n",
        "import math"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Mart&iacute;'s Game"
      ],
      "metadata": {
        "id": "ao5KgjmIvZ7z"
      },
      "id": "ao5KgjmIvZ7z"
    },
    {
      "cell_type": "code",
      "source": [
        "!find . -maxdepth 1 -type d -not -name .\\*"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hOQKnZ948nkx",
        "outputId": "1566314a-8648-4c67-e899-e3ec2d25d034"
      },
      "id": "hOQKnZ948nkx",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "./AlphaZeroFromScratch\n",
            "./AutoML_Zero_Game\n",
            "./sample_data\n",
            "time: 105 ms (started: 2024-04-05 13:53:26 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Valid moves"
      ],
      "metadata": {
        "id": "uDTeAo4Jl9-0"
      },
      "id": "uDTeAo4Jl9-0"
    },
    {
      "cell_type": "code",
      "source": [
        "# s<number> = <number>                  # integer or decimal, can be negative\n",
        "\n",
        "# s<number> = dot(v<number>, v<number>) # dot product operation of two vectors\n",
        "\n",
        "# s<number> = s<number> - s<number>     # subtraction of one s variable from another\n",
        "# s<number> = s<number> * s<number>     # multiplication of one s variable by another\n",
        "\n",
        "# v<number> = s<number> * v<number>     # multiplication of a vector by a scalar\n",
        "# v<number> = v<number> + v<number>     # addition of two vectors\n",
        "\n",
        "import re\n",
        "def check_input(user_input):\n",
        "    patterns = [\n",
        "        r's\\d+\\s*=\\s*-?\\d+(\\.\\d+)?',\n",
        "        r's\\d+\\s*=\\s*dot\\(\\s*v\\d+\\s*,\\s*v\\d+\\s*\\)',\n",
        "        r's\\d+\\s*=\\s*s\\d+\\s*-\\s*s\\d+',\n",
        "        r's\\d+\\s*=\\s*s\\d+\\s*\\*\\s*s\\d+',\n",
        "        r'v\\d+\\s*=\\s*s\\d+\\s*\\*\\s*v\\d+',\n",
        "        r'v\\d+\\s*=\\s*v\\d+\\s*\\+\\s*v\\d+'\n",
        "    ]\n",
        "\n",
        "    for pattern in patterns:\n",
        "        if re.match(pattern, user_input):\n",
        "            return True\n",
        "    return False\n",
        "\n",
        "for s in [\n",
        "    \"s1 = 3.14\",\n",
        "    \"s2 = s1 + s1\", # Not supported\n",
        "    \"s3 = s3 - s3\",\n",
        "    \"v44 = v45 + v46\",\n",
        "    \"v7 = v7 + v7\",\n",
        "    \"v8 = v4 + v4\",\n",
        "    \"s42 = dot( v4 , v2 )\", # Supported after the fix in ecc17b2\n",
        "]:\n",
        "    print(f\"{str(check_input(s)):5s}:\", s)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vf30Dy_7gGcP",
        "outputId": "fb10004d-6894-4376-8bfa-795ee4cc6c65"
      },
      "id": "Vf30Dy_7gGcP",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True : s1 = 3.14\n",
            "False: s2 = s1 + s1\n",
            "True : s3 = s3 - s3\n",
            "True : v44 = v45 + v46\n",
            "True : v7 = v7 + v7\n",
            "True : v8 = v4 + v4\n",
            "True : s42 = dot( v4 , v2 )\n",
            "time: 2.12 ms (started: 2024-04-05 13:53:27 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Convert a statement to scalar and back\n",
        "\n",
        "An encoded statement is 16 bits wide:\n",
        "\n",
        "```\n",
        "0   1   2   3   4   5   6   7   8   9   10  11  12  13  14  15  16\n",
        "|op/label   |dst|dst_index      |sig|exponent       |mantissa   | <-- assignment\n",
        "|2      |1  |1  |4              |1  |4              |3          | (field widths)\n",
        "                                |src1_index     |src2_index     | <-- other ops\n",
        "                                |4              |4              | (field widths)\n",
        "\n",
        "```\n",
        "<!-- * **stage**: Either one of *Setup*, *Predict*, or *Learn*. This is filled in by the `State` class. -->\n",
        "* **op**: Operation code specifies the operation to be performed. This field is 3 bits wide, allowing for up to 8 different operations to be encoded. In the context provided, the operations could be assignments, dot products, subtraction, multiplication, etc.\n",
        "    - **label**: Value 7 (0xF) is special, denoting a stage label.\n",
        "    - Value 6 (0xE) is reserved.\n",
        "* **dst**: Destination type indicator which specifies the type of the destination operand. If this bit is 0, the destination is a scalar (s). If 1, the destination is a vector (v). This allows the system to differentiate between operations targeting scalars or vectors.\n",
        "* **dst_index**: Destination index (dst_index) identifies the specific scalar or vector being operated on. This field is 4 bits wide, supporting indices from 0 to 15. This range should be sufficient for a small vector processing unit or a simple simulation.\n",
        "\n",
        "* **rhs**: The right-hand side (rhs) of the operation encodes two different kinds of information, depending on the *operation* being encoded\n",
        "    - for *assignment operation*:\n",
        "        - **sig**: Signature bit: 1 for negative numbers, 0 for positive numbers\n",
        "        - **exponent**: Biased exponent\n",
        "        - **mantissa**: Scaled mantissa\n",
        "    - for *other operations*:\n",
        "        - **src1_index**, **src2_index**: Source indes (see above)\n",
        "\n",
        "Note that source types are determined by the *operation code* -- this allows us to save two bits."
      ],
      "metadata": {
        "id": "qYmE-v2zmJJ6"
      },
      "id": "qYmE-v2zmJJ6"
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "# Redefine the functions here to ensure the notebook's self-contained execution\n",
        "\n",
        "def encode_floating_point(number: float) -> int:\n",
        "    # Very special cases\n",
        "    if number == 0:\n",
        "        return 0\n",
        "    elif number == 0.001:\n",
        "        return 1\n",
        "\n",
        "    if not 0.001 < abs(number) <= 10:\n",
        "        raise ValueError(f\"Number out of range: {number}.\")\n",
        "\n",
        "    sign_bit = 1 if number < 0 else 0\n",
        "    abs_number = abs(number)\n",
        "\n",
        "    # XXX Handle corner cases our encoding fails at\n",
        "    # For these intervals we would get ~50% error, because the encoding fails\n",
        "    if 0.48 < abs_number < 0.52 or 1.93 < abs_number < 2.23 or 7.75 < abs_number < 8:\n",
        "        candidate1 = abs_number * 0.95\n",
        "        candidate2 = abs_number * 1.04\n",
        "        abs_number = candidate1 if abs(candidate1 - abs_number) < abs(candidate2 - abs_number) else candidate2\n",
        "\n",
        "    exponent = int(np.floor(np.log2(abs_number)))\n",
        "    exponent_bias = 7  # Adjusting bias to support the range\n",
        "    biased_exponent = exponent + exponent_bias\n",
        "\n",
        "    mantissa = (abs_number / (2 ** exponent)) - 1\n",
        "    scaled_mantissa = round(mantissa * 8)  # Scale for 3-bit mantissa\n",
        "\n",
        "    encoded = (sign_bit << 7) | (biased_exponent << 3) | scaled_mantissa\n",
        "    return encoded\n",
        "\n",
        "def decode_floating_point(encoded: int) -> float:\n",
        "    # Very special cases\n",
        "    if encoded == 0:\n",
        "        return 0.0\n",
        "    elif encoded == 1:\n",
        "        return 0.001\n",
        "\n",
        "    sign_bit = encoded >> 7\n",
        "    biased_exponent = (encoded >> 3) & 0b1111\n",
        "    exponent = biased_exponent - 7  # Reversing the bias\n",
        "\n",
        "    scaled_mantissa = encoded & 0b111\n",
        "    mantissa = (scaled_mantissa / 8.0) + 1  # Reverting scale\n",
        "\n",
        "    number = (mantissa * (2 ** exponent)) * (-1 if sign_bit else 1)\n",
        "    return number\n",
        "\n",
        "if False:\n",
        "    # Testing with a range of values\n",
        "    test_values = np.linspace(-10, 10, 1000000)\n",
        "    errors = []\n",
        "\n",
        "    for value in test_values:\n",
        "        if abs(value) < 0.0001:  # Skip values that are too close to zero for this test\n",
        "            errors.append(0)\n",
        "            continue\n",
        "        encoded = encode_floating_point(value)\n",
        "        decoded = decode_floating_point(encoded)\n",
        "        error = abs(decoded - value) / abs(value) * 100 if value != 0 else 0\n",
        "        errors.append(error)\n",
        "\n",
        "    # Plotting the error\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    plt.plot(test_values, errors, label=\"Error Percentage\")\n",
        "    plt.xlabel(\"Original Value\")\n",
        "    plt.ylabel(\"Error Percentage\")\n",
        "    plt.title(\"Error in Encoding and Decoding over 10,000 Values\")\n",
        "    plt.grid(True)\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "# Testing the corrected functions with a new range of values\n",
        "test_values = np.linspace(0.001, 10, 1000, endpoint=False)\n",
        "errors = []\n",
        "bad_numbers = []\n",
        "i = 0\n",
        "for value in test_values:\n",
        "    if abs(value) < 0.0001:  # Skip values that are too close to zero for this test\n",
        "        continue\n",
        "    encoded = encode_floating_point(value)\n",
        "    decoded = decode_floating_point(encoded)\n",
        "    error = abs(decoded - value) / abs(value) * 100\n",
        "    if error > 10:\n",
        "        bad_numbers.append((value, error))\n",
        "\n",
        "print(len(bad_numbers))\n",
        "bad_numbers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBg36pAK9OpW",
        "outputId": "190959de-e09f-4194-e618-44682c1f6eca"
      },
      "id": "MBg36pAK9OpW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(0.030997000000000004, 49.591895989934514),\n",
              " (0.5109490000000001, 10.089265269136428)]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 12.1 ms (started: 2024-04-05 13:53:27 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define the patterns\n",
        "patterns = [\n",
        "    r'(s)(\\d+)\\s*=\\s*(-?\\d+(\\.\\d+)?)', # Assignment to a scalar from a scalar value\n",
        "    r'(s)(\\d+)\\s*=\\s*dot\\(\\s*(v)(\\d+)\\s*,\\s*(v)(\\d+)\\s*\\)', # Dot product\n",
        "    r'(s)(\\d+)\\s*=\\s*(s)(\\d+)\\s*-\\s*(s)(\\d+)', # Subtraction\n",
        "    r'(s)(\\d+)\\s*=\\s*(s)(\\d+)\\s*\\*\\s*(s)(\\d+)', # Multiplication\n",
        "    r'(v)(\\d+)\\s*=\\s*(s)(\\d+)\\s*\\*\\s*(v)(\\d+)', # Scalar and vector multiplication\n",
        "    r'(v)(\\d+)\\s*=\\s*(v)(\\d+)\\s*\\+\\s*(v)(\\d+)' # Vector addition\n",
        "    r' ^this pattern can never match' # Reserved\n",
        "    r'(Setup|Predict|Learn):' # Stage label\n",
        "]\n",
        "compiled_patterns = [re.compile(pattern) for pattern in patterns]\n",
        "\n",
        "INDEX_BITS = 4\n",
        "INDEX_MASK = ((1 << INDEX_BITS) - 1) # 0b1111\n",
        "RHS_BITS = 2 * INDEX_BITS\n",
        "RHS_MASK = ((1 << RHS_BITS) - 1) # 0x3FF\n",
        "STAGE_LABEL_PREAMBLE = 0b1110_0000_0000_0000\n",
        "\n",
        "def move_to_scalar(s: str) -> int:  # -> int16\n",
        "    \"\"\"\n",
        "    Returns:\n",
        "        int: 16-bit scalar representing the move\n",
        "    \"\"\"\n",
        "    try:\n",
        "        stage = Stage.from_value(s.strip().rstrip(\":\"), raise_exception=True)\n",
        "        # It's a stage label\n",
        "        return STAGE_LABEL_PREAMBLE | stage\n",
        "    except ValueError: pass\n",
        "    op = None\n",
        "    is_assignment = False\n",
        "    for i, pattern in enumerate(compiled_patterns):\n",
        "        match = pattern.match(s)\n",
        "        if match:\n",
        "            op = i\n",
        "            dst_type, dst_index = match.group(1), int(match.group(2))\n",
        "            assert dst_type in ['v', 's']\n",
        "            assert dst_index < 2 ** INDEX_BITS\n",
        "            if i == 0: # Assignment\n",
        "                scalar_value = float(match.group(3))\n",
        "                rhs = encode_floating_point(scalar_value)\n",
        "            else:\n",
        "                src1_type, src1_index = match.group(3), int(match.group(4))\n",
        "                src2_type, src2_index = match.group(5), int(match.group(6))\n",
        "                rhs = (src1_index << INDEX_BITS) | src2_index\n",
        "            break\n",
        "\n",
        "    if op is None:\n",
        "        raise ValueError(f\"Invalid operation: {s}\")\n",
        "\n",
        "    enc = (op << (1 + INDEX_BITS + RHS_BITS)) | ((0 if dst_type == 's' else 1) << (INDEX_BITS + RHS_BITS)) | (dst_index << RHS_BITS) | rhs\n",
        "    return enc\n",
        "\n",
        "# Example usage\n",
        "print(move_to_scalar(\"s0 = s0 - s0\"))\n",
        "print(move_to_scalar(\"s7 = dot(v7,v7)\"))\n",
        "print(move_to_scalar(\"s8 = 3.141\"))\n",
        "print(move_to_scalar(\"s0 = 3.141\"))\n",
        "print(move_to_scalar(\"s1 = 3.141\"))\n",
        "\n",
        "\n",
        "def scalar_to_move(enc: int) -> str:\n",
        "    op_index = enc >> (RHS_BITS + INDEX_BITS + 1)\n",
        "    dst_type_flag = (enc >> (RHS_BITS + INDEX_BITS)) & 1\n",
        "    dst_index = (enc >> RHS_BITS) & INDEX_MASK\n",
        "    rhs = enc & RHS_MASK\n",
        "\n",
        "    dst_type = 'v' if dst_type_flag else 's'\n",
        "\n",
        "    if op_index == 0:\n",
        "        scalar_value = decode_floating_point(rhs)\n",
        "        return f\"{dst_type}{dst_index} = {scalar_value}\"\n",
        "    elif op_index == 0x7:\n",
        "        stage = Stage(enc & 0b11)\n",
        "        return f\"{stage}:\"\n",
        "    else:\n",
        "        src2_index = rhs & INDEX_MASK\n",
        "        src1_index = (rhs >> INDEX_BITS) & INDEX_MASK\n",
        "\n",
        "        if op_index == 1:\n",
        "            return f\"{dst_type}{dst_index} = dot(v{src1_index}, v{src2_index})\"\n",
        "        elif op_index == 2:\n",
        "            return f\"{dst_type}{dst_index} = s{src1_index} - s{src2_index}\"\n",
        "        elif op_index == 3:\n",
        "            return f\"{dst_type}{dst_index} = s{src1_index} * s{src2_index}\"\n",
        "        elif op_index == 4:\n",
        "            return f\"{dst_type}{dst_index} = s{src1_index} * v{src2_index}\"\n",
        "        elif op_index == 5:\n",
        "            return f\"{dst_type}{dst_index} = v{src1_index} + v{src2_index}\"\n",
        "        else:\n",
        "            return \"Unknown operation\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ulk8Po98mM_f",
        "outputId": "2a222688-345b-46bc-9898-15874443442b"
      },
      "id": "Ulk8Po98mM_f",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "16384\n",
            "10103\n",
            "2117\n",
            "69\n",
            "325\n",
            "time: 3.27 ms (started: 2024-04-05 13:53:27 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete and correct the sample strings\n",
        "samples = [\n",
        "    \"s0 = -10\",\n",
        "    \"s10 = 10\",\n",
        "    \"s1 = 3.141\",\n",
        "    \"s2 = 3.141\",\n",
        "    \"s3 = 9\",\n",
        "    \"s2 = dot(v1, v2)\",\n",
        "    \"s3 = s1 - s2\",\n",
        "    \"s4 = s3 * s2\",\n",
        "    \"v4 = s3 * v5\",\n",
        "    \"v6 = v4 + v5\",\n",
        "    \"s7 = 0\",\n",
        "    \"s8 = dot(v2, v3)\",\n",
        "    \"s9 = s7 * s8\",\n",
        "    \"v10 = s9 * v9\",\n",
        "    \"v11 = v10 + v0\"\n",
        "]\n",
        "\n",
        "# Roundtrip conversion\n",
        "results = []\n",
        "for sample in samples:\n",
        "    enc = move_to_scalar(sample)\n",
        "    roundtrip_sample = scalar_to_move(enc)\n",
        "    result = sample == roundtrip_sample\n",
        "    if not result:\n",
        "        result = f\"{sample}.0\" == roundtrip_sample\n",
        "    results.append((sample, roundtrip_sample, result))\n",
        "\n",
        "results"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KkBVzsaqqrEQ",
        "outputId": "fe3fca91-1ad2-4476-d302-8deb8f324014"
      },
      "id": "KkBVzsaqqrEQ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('s0 = -10', 's0 = -10.0', True),\n",
              " ('s10 = 10', 's10 = 10.0', True),\n",
              " ('s1 = 3.141', 's1 = 3.25', False),\n",
              " ('s2 = 3.141', 's2 = 3.25', False),\n",
              " ('s3 = 9', 's3 = 9.0', True),\n",
              " ('s2 = dot(v1, v2)', 's2 = dot(v1, v2)', True),\n",
              " ('s3 = s1 - s2', 's3 = s1 - s2', True),\n",
              " ('s4 = s3 * s2', 's4 = s3 * s2', True),\n",
              " ('v4 = s3 * v5', 'v4 = s3 * v5', True),\n",
              " ('v6 = v4 + v5', 'v6 = v4 + v5', True),\n",
              " ('s7 = 0', 's7 = 0.0', True),\n",
              " ('s8 = dot(v2, v3)', 's8 = dot(v2, v3)', True),\n",
              " ('s9 = s7 * s8', 's9 = s7 * s8', True),\n",
              " ('v10 = s9 * v9', 'v10 = s9 * v9', True),\n",
              " ('v11 = v10 + v0', 'v11 = v10 + v0', True)]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 3.67 ms (started: 2024-04-05 13:53:27 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from contextlib import contextmanager\n",
        "import json\n",
        "\n",
        "from typing import Any, Tuple, Union\n",
        "from numpy.typing import NDArray\n",
        "import numpy as np\n",
        "from enum import IntEnum\n",
        "\n",
        "\n",
        "\n",
        "# Make relative imports, and, most importantly, Bazel, work\n",
        "GAME_DIR = 'AutoML_Zero_Game'\n",
        "@contextmanager\n",
        "def cd(game_dir: str):\n",
        "    \"\"\"Temporarily change directory to game_dir\"\"\"\n",
        "    original_dir = os.getcwd()  # Save the original working directory\n",
        "    try:\n",
        "        # Change to the desired directory if not already there\n",
        "        if original_dir.split(os.sep)[-1] != game_dir:\n",
        "            new_dir = os.path.join(original_dir, game_dir)\n",
        "            if os.path.isdir(new_dir):\n",
        "                os.chdir(new_dir)\n",
        "                # print(f\"Changed directory to {new_dir}\")\n",
        "            else:\n",
        "                raise RuntimeError(f\"The directory {new_dir} does not exist.\")\n",
        "        yield  # This allows the code within the `with` block to run\n",
        "    finally:\n",
        "        # Change back to the original directory\n",
        "        os.chdir(original_dir)\n",
        "        # print(f\"Reverted to the original directory {original_dir}\")\n",
        "\n",
        "# from Game import Round\n",
        "with cd(GAME_DIR):\n",
        "    from enter_alg import enter_alg\n",
        "    from evaluator import evaluate\n",
        "\n",
        "class Player:\n",
        "    def __init__(self, value):\n",
        "        self.score = 0.0\n",
        "        assert(1 in [value, -value])\n",
        "        self.value = value\n",
        "\n",
        "class Statement:\n",
        "    def __init__(self, s: str):\n",
        "        self.as_string = s\n",
        "        self.encoded = __class__.encode(s)\n",
        "        self.my_type = self.compute_type(s)\n",
        "\n",
        "    def __repr__(self) -> Union[int,None]:\n",
        "        return self.encoded\n",
        "\n",
        "    @classmethod\n",
        "    def encode(cls, s: Union[str,None]) -> Union[int,None]:\n",
        "        if s is None:\n",
        "            return None\n",
        "        else:\n",
        "            return move_to_scalar(s)\n",
        "\n",
        "    @classmethod\n",
        "    def decode(cls, enc: Union[int|None]) -> Union[str|None]:\n",
        "        if enc is None:\n",
        "            return None\n",
        "        else:\n",
        "            return scalar_to_move(enc)\n",
        "\n",
        "    def compute_type(self):\n",
        "        # patterns = [\n",
        "        #     r'(s)(\\d+)\\s*=\\s*(-?\\d+(\\.\\d+)?)', # Assignment to a scalar from a scalar value\n",
        "        #     r'(s)(\\d+)\\s*=\\s*dot\\(\\s*(v)(\\d+)\\s*,\\s*(v)(\\d+)\\s*\\)', # Dot product\n",
        "        #     r'(s)(\\d+)\\s*=\\s*(s)(\\d+)\\s*-\\s*(s)(\\d+)', # Subtraction\n",
        "        #     r'(s)(\\d+)\\s*=\\s*(s)(\\d+)\\s*\\*\\s*(s)(\\d+)', # Multiplication\n",
        "        #     r'(v)(\\d+)\\s*=\\s*(s)(\\d+)\\s*\\*\\s*(v)(\\d+)', # Scalar and vector multiplication\n",
        "        #     r'(v)(\\d+)\\s*=\\s*(v)(\\d+)\\s*\\+\\s*(v)(\\d+)' # Vector addition\n",
        "        # ]\n",
        "        # compiled_patterns = [re.compile(pattern) for pattern in patterns]\n",
        "        TYPES = [\n",
        "            \"ASSIGNMENT\",            # scalar = 3.14\n",
        "            \"DOT_PRODUCT\",           # dot(vector, vector)\n",
        "            \"SUBTRACTION\",           # scalar - scalar\n",
        "            \"MULTIPLICATION_SCALAR\", # scalar * vector\n",
        "            \"MULTIPLICATION_VECTOR\", # vector * vector\n",
        "            \"ADDITION\",              # vector + vector\n",
        "            \"_RESERVED\",\n",
        "            \"STAGE_LABEL\",           # \"Setup:\" / \"Predict:\" / \"Learn:\"\n",
        "        ]\n",
        "        for i, pattern in enumerate(compiled_patterns):\n",
        "            if pattern.match(s):\n",
        "                return TYPES[i]\n",
        "\n",
        "    def allowed_mutations(self):\n",
        "        allowed = [\"DESTINATION_INDEX\"]\n",
        "        if self.my_type == \"ASSIGNMENT\":\n",
        "            allowed.append(\"CONSTANT\")\n",
        "        else:\n",
        "            allowed.append(\"SOURCE1_INDEX\")\n",
        "            allowed.append(\"SOURCE2_INDEX\")\n",
        "\n",
        "class Stage(IntEnum):\n",
        "    UNDEFINED = 0b00\n",
        "    SETUP = 0b01\n",
        "    PREDICT = 0b10\n",
        "    LEARN = 0b11\n",
        "\n",
        "    @classmethod\n",
        "    def from_value(cls, value, raise_exception=False):\n",
        "        # Direct check for valid enum values\n",
        "        if isinstance(value, cls):\n",
        "            return value\n",
        "        if isinstance(value, int) and value in cls._value2member_map_:\n",
        "            return cls(value)\n",
        "\n",
        "        s = str(value).capitalize()\n",
        "        if s == \"Setup\":\n",
        "            return cls.SETUP\n",
        "        elif s == \"Predict\":\n",
        "            return cls.PREDICT\n",
        "        elif s == \"Learn\":\n",
        "            return cls.LEARN\n",
        "        elif not raise_exception:\n",
        "            return cls.UNDEFINED\n",
        "        else:\n",
        "            raise ValueError(f\"Bad value for Stage: >>{value}<<\")\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        \"\"\"Return the string representation as required\"\"\"\n",
        "        if self == Stage.SETUP:\n",
        "            return \"Setup\"\n",
        "        elif self == Stage.PREDICT:\n",
        "            return \"Predict\"\n",
        "        elif self == Stage.LEARN:\n",
        "            return \"Learn\"\n",
        "        else:\n",
        "            return \"Undefined\"\n",
        "\n",
        "class State:\n",
        "    \"\"\"\n",
        "    A state is a Numpy array of int16 values representing individual statements.\n",
        "    The number of statements in a state is configurable, and should be kept small.\n",
        "\n",
        "    Labels are treated just as statements.\n",
        "    \"\"\"\n",
        "    def __init__(self, s: str):\n",
        "        self.as_string = s\n",
        "        self.encoded = __class__.encode(s)\n",
        "\n",
        "    def __str__(self) -> str:\n",
        "        return self.as_string\n",
        "\n",
        "    def __repr__(self):\n",
        "        return self.encoded\n",
        "\n",
        "    @classmethod\n",
        "    def decode(cls, enc: NDArray[np.int16]) -> str:\n",
        "        return '\\n'.join([Statement.decode(x) for x in enc])\n",
        "\n",
        "    @classmethod\n",
        "    def encode(cls, s: str) -> NDArray[np.int16]:\n",
        "        lines = s.strip().split('\\n')\n",
        "        enc = [Statement.encode(line) for line in lines]\n",
        "        return np.array(enc, dtype=np.int16)\n",
        "\n",
        "class MartisGame:\n",
        "    num_resBlocks = -1\n",
        "    num_hidden = -1\n",
        "\n",
        "    def __init__(self):\n",
        "        self.player1 = Player(1)\n",
        "        self.player2 = Player(-1)\n",
        "\n",
        "    def __init__(self) -> None:\n",
        "        self.player1: Player = Player(1)\n",
        "        self.player2: Player = Player(-1)\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return str(self.__class__.__name__)\n",
        "\n",
        "    def get_initial_state(self) -> NDArray[np.int16]:\n",
        "        EMPTY_STATE = \"Setup:\\nPredict:\\nLearn:\"\n",
        "        state = State(EMPTY_STATE)\n",
        "        return state\n",
        "\n",
        "    def get_next_state(self, state: NDArray[Any], action: Any, player: int) -> Tuple[NDArray[np.uint16], int]:\n",
        "        with cd(GAME_DIR):\n",
        "            raise NotImplementedError()\n",
        "\n",
        "    def get_valid_moves(self, state: NDArray[Any]) -> NDArray[np.uint8]:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def check_win(self, state: NDArray[Any], action: Union[Any, None]) -> bool:\n",
        "        if action == None:\n",
        "            return False\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_value_and_terminated(self, state: NDArray[Any], action: Union[Any, None]) -> Tuple[float, bool]:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_opponent(self, player: int) -> int:\n",
        "        return -player\n",
        "\n",
        "    def get_opponent_value(self, value: float) -> float:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def change_perspective(self, state: NDArray[Any], player: int) -> NDArray[Any]:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_encoded_state(self, state: NDArray[Any]) -> NDArray[Any]:\n",
        "        raise NotImplementedError()\n",
        "\n",
        "if \"MartisGame\" not in CONFIG:\n",
        "    CONFIG[\"MartisGame\"] = {}\n",
        "CONFIG[\"MartisGame\"][\"ResNet\"] = {\n",
        "    \"num_resBlocks\": MartisGame.num_resBlocks,\n",
        "    \"num_hidden\": MartisGame.num_hidden,\n",
        "}\n",
        "print(json.dumps(CONFIG[\"MartisGame\"], indent=4))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wClOy3Z3vmaL",
        "outputId": "ef01befc-ce71-40f5-8c35-8fe19cb88a5d"
      },
      "id": "wClOy3Z3vmaL",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{\n",
            "    \"ResNet\": {\n",
            "        \"num_resBlocks\": -1,\n",
            "        \"num_hidden\": -1\n",
            "    }\n",
            "}\n",
            "time: 8.93 ms (started: 2024-04-05 13:53:27 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tic Tac Toe"
      ],
      "metadata": {
        "id": "z1E7UalFvjjj"
      },
      "id": "z1E7UalFvjjj"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a097e1b5",
      "metadata": {
        "id": "a097e1b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "72326a55-c800-4db0-b76d-39d93349b29b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.11 ms (started: 2024-04-05 13:53:27 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class TicTacToe:\n",
        "    def __init__(self):\n",
        "        self.row_count = 3\n",
        "        self.column_count = 3\n",
        "        self.action_size = self.row_count * self.column_count\n",
        "\n",
        "    def __repr__(self):\n",
        "        return \"TicTacToe\"\n",
        "\n",
        "    def get_initial_state(self):\n",
        "        return np.zeros((self.row_count, self.column_count))\n",
        "\n",
        "    def get_next_state(self, state, action, player):\n",
        "        row = action // self.column_count\n",
        "        column = action % self.column_count\n",
        "        state[row, column] = player\n",
        "        return state\n",
        "\n",
        "    def get_valid_moves(self, state):\n",
        "        return (state.reshape(-1) == 0).astype(np.uint8)\n",
        "\n",
        "    def check_win(self, state, action):\n",
        "        if action == None:\n",
        "            return False\n",
        "\n",
        "        row = action // self.column_count\n",
        "        column = action % self.column_count\n",
        "        player = state[row, column]\n",
        "\n",
        "        return (\n",
        "            np.sum(state[row, :]) == player * self.column_count\n",
        "            or np.sum(state[:, column]) == player * self.row_count\n",
        "            or np.sum(np.diag(state)) == player * self.row_count\n",
        "            or np.sum(np.diag(np.flip(state, axis=0))) == player * self.row_count\n",
        "        )\n",
        "\n",
        "    def get_value_and_terminated(self, state, action):\n",
        "        if self.check_win(state, action):\n",
        "            return 1, True\n",
        "        if np.sum(self.get_valid_moves(state)) == 0:\n",
        "            return 0, True\n",
        "        return 0, False\n",
        "\n",
        "    def get_opponent(self, player):\n",
        "        return -player\n",
        "\n",
        "    def get_opponent_value(self, value):\n",
        "        return -value\n",
        "\n",
        "    def change_perspective(self, state, player):\n",
        "        return state * player\n",
        "\n",
        "    def get_encoded_state(self, state):\n",
        "        encoded_state = np.stack(\n",
        "            (state == -1, state == 0, state == 1)\n",
        "        ).astype(np.float32)\n",
        "\n",
        "        if len(state.shape) == 3:\n",
        "            encoded_state = np.swapaxes(encoded_state, 0, 1)\n",
        "\n",
        "        return encoded_state"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Connect Four"
      ],
      "metadata": {
        "id": "ZgRPuIpT1GN7"
      },
      "id": "ZgRPuIpT1GN7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "682c4ca4",
      "metadata": {
        "id": "682c4ca4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c742f484-3646-43fd-eb4c-e1ef81cbb97b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.5 ms (started: 2024-04-05 13:53:27 +00:00)\n"
          ]
        }
      ],
      "source": [
        "from numpy.typing import NDArray\n",
        "import numpy as np\n",
        "from typing import Tuple, Union, Any\n",
        "\n",
        "class ConnectFour:\n",
        "    def __init__(self):\n",
        "        self.row_count = 6\n",
        "        self.column_count = 7\n",
        "        self.action_size = self.column_count\n",
        "        self.in_a_row = 4\n",
        "\n",
        "    def __repr__(self) -> str:\n",
        "        return \"ConnectFour\"\n",
        "\n",
        "    def get_initial_state(self) -> NDArray[np.float64]:\n",
        "        return np.zeros((self.row_count, self.column_count))\n",
        "\n",
        "    def get_next_state(self, state: NDArray[np.float64], action: int, player: int) -> NDArray[np.float64]:\n",
        "        row = np.max(np.where(state[:, action] == 0))\n",
        "        state[row, action] = player\n",
        "        return state\n",
        "\n",
        "    def get_valid_moves(self, state: NDArray[np.float64]) -> NDArray[np.uint8]:\n",
        "        return (state[0] == 0).astype(np.uint8)\n",
        "\n",
        "    def check_win(self, state: NDArray[np.float64], action: Union[int, None]) -> bool:\n",
        "        if action == None:\n",
        "            return False\n",
        "\n",
        "        row = np.min(np.where(state[:, action] != 0))\n",
        "        column = action\n",
        "        player = state[row][column]\n",
        "\n",
        "        def count(offset_row, offset_column):\n",
        "            for i in range(1, self.in_a_row):\n",
        "                r = row + offset_row * i\n",
        "                c = action + offset_column * i\n",
        "                if (\n",
        "                    r < 0\n",
        "                    or r >= self.row_count\n",
        "                    or c < 0\n",
        "                    or c >= self.column_count\n",
        "                    or state[r][c] != player\n",
        "                ):\n",
        "                    return i - 1\n",
        "            return self.in_a_row - 1\n",
        "\n",
        "        return (\n",
        "            count(1, 0) >= self.in_a_row - 1 # vertical\n",
        "            or (count(0, 1) + count(0, -1)) >= self.in_a_row - 1 # horizontal\n",
        "            or (count(1, 1) + count(-1, -1)) >= self.in_a_row - 1 # top left diagonal\n",
        "            or (count(1, -1) + count(-1, 1)) >= self.in_a_row - 1 # top right diagonal\n",
        "        )\n",
        "\n",
        "    def get_value_and_terminated(self, state: NDArray[np.float64], action: Union[int, None]) -> Tuple[int, bool]:\n",
        "        if self.check_win(state, action):\n",
        "            return 1, True\n",
        "        if np.sum(self.get_valid_moves(state)) == 0:\n",
        "            return 0, True\n",
        "        return 0, False\n",
        "\n",
        "    def get_opponent(self, player: int) -> int:\n",
        "        return -player\n",
        "\n",
        "    def get_opponent_value(self, value: int) -> int:\n",
        "        return -value\n",
        "\n",
        "    def change_perspective(self, state: NDArray[np.float64], player: int) -> NDArray[np.float64]:\n",
        "        return state * player\n",
        "\n",
        "    def get_encoded_state(self, state: NDArray[np.float64]) -> NDArray[Any]:\n",
        "        encoded_state = np.stack(\n",
        "            (state == -1, state == 0, state == 1)\n",
        "        ).astype(np.float32)\n",
        "\n",
        "        if len(state.shape) == 3:\n",
        "            encoded_state = np.swapaxes(encoded_state, 0, 1)\n",
        "\n",
        "        return encoded_state"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet"
      ],
      "metadata": {
        "id": "u8LIKCjU1KPw"
      },
      "id": "u8LIKCjU1KPw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "02e5b58b",
      "metadata": {
        "id": "02e5b58b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a642b8af-6923-416f-e99b-7007294720c8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.33 ms (started: 2024-04-05 13:53:27 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class ResNet(nn.Module):\n",
        "    def __init__(self, game, num_resBlocks, num_hidden, device):\n",
        "        super().__init__()\n",
        "\n",
        "        self.device = device\n",
        "        self.startBlock = nn.Sequential(\n",
        "            nn.Conv2d(3, num_hidden, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(num_hidden),\n",
        "            nn.ReLU()\n",
        "        )\n",
        "\n",
        "        self.backBone = nn.ModuleList(\n",
        "            [ResBlock(num_hidden) for i in range(num_resBlocks)]\n",
        "        )\n",
        "\n",
        "        self.policyHead = nn.Sequential(\n",
        "            nn.Conv2d(num_hidden, 32, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(32),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(32 * game.row_count * game.column_count, game.action_size)\n",
        "        )\n",
        "\n",
        "        self.valueHead = nn.Sequential(\n",
        "            nn.Conv2d(num_hidden, 3, kernel_size=3, padding=1),\n",
        "            nn.BatchNorm2d(3),\n",
        "            nn.ReLU(),\n",
        "            nn.Flatten(),\n",
        "            nn.Linear(3 * game.row_count * game.column_count, 1),\n",
        "            nn.Tanh()\n",
        "        )\n",
        "\n",
        "        self.to(device)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.startBlock(x)\n",
        "        for resBlock in self.backBone:\n",
        "            x = resBlock(x)\n",
        "        policy = self.policyHead(x)\n",
        "        value = self.valueHead(x)\n",
        "        return policy, value\n",
        "\n",
        "\n",
        "class ResBlock(nn.Module):\n",
        "    def __init__(self, num_hidden):\n",
        "        super().__init__()\n",
        "        self.conv1 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
        "        self.bn1 = nn.BatchNorm2d(num_hidden)\n",
        "        self.conv2 = nn.Conv2d(num_hidden, num_hidden, kernel_size=3, padding=1)\n",
        "        self.bn2 = nn.BatchNorm2d(num_hidden)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = F.relu(self.bn1(self.conv1(x)))\n",
        "        x = self.bn2(self.conv2(x))\n",
        "        x += residual\n",
        "        x = F.relu(x)\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Test harness interface is working"
      ],
      "metadata": {
        "id": "vbp7HXWt1TnL"
      },
      "id": "vbp7HXWt1TnL"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "CONFIG[\"TicTacToe\"][\"moves\"] = [\n",
        "    (2, -1),\n",
        "    (4, -1),\n",
        "    (6, 1),\n",
        "    (8, 1),\n",
        "]\n",
        "CONFIG[\"ConnectFour\"][\"moves\"] = [\n",
        "    # columns 0..6\n",
        "    (0, 1),\n",
        "    (0, -1),\n",
        "    (1, 1),\n",
        "    (1, -1),\n",
        "    (2, 1),\n",
        "    (2, -1),\n",
        "    (3, 1),\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "def test_harness(game_name):\n",
        "    game = globals()[game_name]()\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    if game_name not in CONFIG:\n",
        "        raise NotImplementedError(f\"Not a known name: {game_name}\")\n",
        "\n",
        "    game_config = CONFIG[game_name]\n",
        "    num_resBlocks = game_config[\"ResNet\"][\"num_resBlocks\"]\n",
        "    num_hidden = game_config[\"ResNet\"][\"num_hidden\"]\n",
        "    model_file_name = game_config[\"model\"]\n",
        "\n",
        "    state = game.get_initial_state()\n",
        "    for move in game_config[\"moves\"]:\n",
        "        position = move[0]\n",
        "        player = move[1]\n",
        "        state = game.get_next_state(state, position, player)\n",
        "\n",
        "    encoded_state = game.get_encoded_state(state)\n",
        "    tensor_state = torch.tensor(encoded_state, device=device).unsqueeze(0)\n",
        "\n",
        "\n",
        "    print(f\"DEBUG: game is {repr(game)}\")\n",
        "    model = ResNet(game, num_resBlocks, num_hidden, device=device)\n",
        "    model.load_state_dict(torch.load(model_file_name, map_location=device))\n",
        "\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    policy, value = model(tensor_state)\n",
        "    value = value.item()\n",
        "    policy = torch.softmax(policy, axis=1).squeeze(0).detach().cpu().numpy()\n",
        "\n",
        "    print(value)\n",
        "\n",
        "    print(state)\n",
        "    print(tensor_state)\n",
        "\n",
        "    plt.bar(range(game.action_size), policy)\n",
        "    plt.show()\n",
        "\n",
        "for game_name in CONFIG:\n",
        "    print(f\"Testing {game_name}...\")\n",
        "    try:\n",
        "        test_harness(game_name)\n",
        "    except Exception as e:\n",
        "        print(f\"ERROR testing {game_name}: {repr(e)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DBWspblt4NnZ",
        "outputId": "0b107e81-130e-48f2-9367-e8435a87b6dc"
      },
      "id": "DBWspblt4NnZ",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing TicTacToe...\n",
            "DEBUG: game is TicTacToe\n",
            "0.9852450489997864\n",
            "[[ 0.  0. -1.]\n",
            " [ 0. -1.  0.]\n",
            " [ 1.  0.  1.]]\n",
            "tensor([[[[0., 0., 1.],\n",
            "          [0., 1., 0.],\n",
            "          [0., 0., 0.]],\n",
            "\n",
            "         [[1., 1., 0.],\n",
            "          [1., 0., 1.],\n",
            "          [0., 1., 0.]],\n",
            "\n",
            "         [[0., 0., 0.],\n",
            "          [0., 0., 0.],\n",
            "          [1., 0., 1.]]]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing ConnectFour...\n",
            "DEBUG: game is ConnectFour\n",
            "0.9972138404846191\n",
            "[[ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [ 0.  0.  0.  0.  0.  0.  0.]\n",
            " [-1. -1. -1.  0.  0.  0.  0.]\n",
            " [ 1.  1.  1.  1.  0.  0.  0.]]\n",
            "tensor([[[[0., 0., 0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0., 0., 0.],\n",
            "          [1., 1., 1., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0., 0., 0.]],\n",
            "\n",
            "         [[1., 1., 1., 1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1., 1., 1., 1.],\n",
            "          [1., 1., 1., 1., 1., 1., 1.],\n",
            "          [0., 0., 0., 1., 1., 1., 1.],\n",
            "          [0., 0., 0., 0., 1., 1., 1.]],\n",
            "\n",
            "         [[0., 0., 0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0., 0., 0.],\n",
            "          [0., 0., 0., 0., 0., 0., 0.],\n",
            "          [1., 1., 1., 1., 0., 0., 0.]]]], device='cuda:0')\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Testing MartisGame...\n",
            "ERROR testing MartisGame: KeyError('model')\n",
            "time: 1.44 s (started: 2024-04-05 13:53:27 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x5J6CzTq-ZvY",
        "outputId": "29f67596-7c3c-471d-9de8-e90203bff5a1"
      },
      "id": "x5J6CzTq-ZvY",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AlphaZeroFromScratch\t\t       model_2.pt\t       optimizer_7_ConnectFour.pt\n",
            "AutoML_Zero_Game\t\t       model_7_ConnectFour.pt  sample_data\n",
            "bazel-3.7.2-installer-linux-x86_64.sh  optimizer_2.pt\n",
            "time: 106 ms (started: 2024-04-05 13:53:28 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Node"
      ],
      "metadata": {
        "id": "h-Fr1Dey1Y6D"
      },
      "id": "h-Fr1Dey1Y6D"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "21866526",
      "metadata": {
        "id": "21866526",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84f2279a-0887-4f02-c956-ec317dc8ef96"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.9 ms (started: 2024-04-05 13:53:28 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class Node:\n",
        "    def __init__(self, game, args, state, parent=None, action_taken=None, prior=0, visit_count=0):\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.state = state\n",
        "        self.parent = parent\n",
        "        self.action_taken = action_taken\n",
        "        self.prior = prior\n",
        "\n",
        "        self.children = []\n",
        "\n",
        "        self.visit_count = visit_count\n",
        "        self.value_sum = 0\n",
        "\n",
        "    def is_fully_expanded(self):\n",
        "        return len(self.children) > 0\n",
        "\n",
        "    def select(self):\n",
        "        best_child = None\n",
        "        best_ucb = -np.inf\n",
        "\n",
        "        for child in self.children:\n",
        "            ucb = self.get_ucb(child)\n",
        "            if ucb > best_ucb:\n",
        "                best_child = child\n",
        "                best_ucb = ucb\n",
        "\n",
        "        return best_child\n",
        "\n",
        "    def get_ucb(self, child):\n",
        "        if child.visit_count == 0:\n",
        "            q_value = 0\n",
        "        else:\n",
        "            q_value = 1 - ((child.value_sum / child.visit_count) + 1) / 2\n",
        "        return q_value + self.args['C'] * (math.sqrt(self.visit_count) / (child.visit_count + 1)) * child.prior\n",
        "\n",
        "    def expand(self, policy):\n",
        "        for action, prob in enumerate(policy):\n",
        "            if prob > 0:\n",
        "                child_state = self.state.copy()\n",
        "                child_state = self.game.get_next_state(child_state, action, 1)\n",
        "                child_state = self.game.change_perspective(child_state, player=-1)\n",
        "\n",
        "                child = Node(self.game, self.args, child_state, self, action, prob)\n",
        "                self.children.append(child)\n",
        "\n",
        "        return child\n",
        "\n",
        "    def backpropagate(self, value):\n",
        "        self.value_sum += value\n",
        "        self.visit_count += 1\n",
        "\n",
        "        value = self.game.get_opponent_value(value)\n",
        "        if self.parent is not None:\n",
        "            self.parent.backpropagate(value)\n",
        "\n",
        "\n",
        "class MCTS:\n",
        "    def __init__(self, game, args, model):\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.model = model\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def search(self, state):\n",
        "        root = Node(self.game, self.args, state, visit_count=1)\n",
        "\n",
        "        policy, _ = self.model(\n",
        "            torch.tensor(self.game.get_encoded_state(state), device=self.model.device).unsqueeze(0)\n",
        "        )\n",
        "        policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n",
        "        policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n",
        "            * np.random.dirichlet([self.args['dirichlet_alpha']] * self.game.action_size)\n",
        "\n",
        "        valid_moves = self.game.get_valid_moves(state)\n",
        "        policy *= valid_moves\n",
        "        policy /= np.sum(policy)\n",
        "        root.expand(policy)\n",
        "\n",
        "        for search in range(self.args['num_searches']):\n",
        "            node = root\n",
        "\n",
        "            while node.is_fully_expanded():\n",
        "                node = node.select()\n",
        "\n",
        "            value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n",
        "            value = self.game.get_opponent_value(value)\n",
        "\n",
        "            if not is_terminal:\n",
        "                policy, value = self.model(\n",
        "                    torch.tensor(self.game.get_encoded_state(node.state), device=self.model.device).unsqueeze(0)\n",
        "                )\n",
        "                policy = torch.softmax(policy, axis=1).squeeze(0).cpu().numpy()\n",
        "                valid_moves = self.game.get_valid_moves(node.state)\n",
        "                policy *= valid_moves\n",
        "                policy /= np.sum(policy)\n",
        "\n",
        "                value = value.item()\n",
        "\n",
        "                node.expand(policy)\n",
        "\n",
        "            node.backpropagate(value)\n",
        "\n",
        "\n",
        "        action_probs = np.zeros(self.game.action_size)\n",
        "        for child in root.children:\n",
        "            action_probs[child.action_taken] = child.visit_count\n",
        "        action_probs /= np.sum(action_probs)\n",
        "        return action_probs\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AlphaZero"
      ],
      "metadata": {
        "id": "-MtBUrqH1eC6"
      },
      "id": "-MtBUrqH1eC6"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a3b28ab8",
      "metadata": {
        "id": "a3b28ab8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11e9fe26-f560-4ae5-d414-e96a8772ba74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.59 ms (started: 2024-04-05 13:53:28 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class AlphaZero:\n",
        "    def __init__(self, model, optimizer, game, args):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.mcts = MCTS(game, args, model)\n",
        "\n",
        "    def selfPlay(self):\n",
        "        memory = []\n",
        "        player = 1\n",
        "        state = self.game.get_initial_state()\n",
        "\n",
        "        while True:\n",
        "            neutral_state = self.game.change_perspective(state, player)\n",
        "            action_probs = self.mcts.search(neutral_state)\n",
        "\n",
        "            memory.append((neutral_state, action_probs, player))\n",
        "\n",
        "            temperature_action_probs = action_probs ** (1 / self.args['temperature']) # Divide temperature_action_probs with its sum in case of an error\n",
        "            # Normalize temperature_action_probs so that its values sum to 1 by dividing it by its sum:\n",
        "            temperature_action_probs /= np.sum(temperature_action_probs) # Fixes: A ValueError is raised with the message \"probabilities do not sum to 1\".\n",
        "            action = np.random.choice(self.game.action_size, p=temperature_action_probs)\n",
        "\n",
        "            state = self.game.get_next_state(state, action, player)\n",
        "\n",
        "            value, is_terminal = self.game.get_value_and_terminated(state, action)\n",
        "\n",
        "            if is_terminal:\n",
        "                returnMemory = []\n",
        "                for hist_neutral_state, hist_action_probs, hist_player in memory:\n",
        "                    hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n",
        "                    returnMemory.append((\n",
        "                        self.game.get_encoded_state(hist_neutral_state),\n",
        "                        hist_action_probs,\n",
        "                        hist_outcome\n",
        "                    ))\n",
        "                return returnMemory\n",
        "\n",
        "            player = self.game.get_opponent(player)\n",
        "\n",
        "    def train(self, memory):\n",
        "        random.shuffle(memory)\n",
        "        for batchIdx in range(0, len(memory), self.args['batch_size']):\n",
        "            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])] # Change to memory[batchIdx:batchIdx+self.args['batch_size']] in case of an error\n",
        "            state, policy_targets, value_targets = zip(*sample)\n",
        "\n",
        "            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
        "\n",
        "            state = torch.tensor(state, dtype=torch.float32, device=self.model.device)\n",
        "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32, device=self.model.device)\n",
        "            value_targets = torch.tensor(value_targets, dtype=torch.float32, device=self.model.device)\n",
        "\n",
        "            out_policy, out_value = self.model(state)\n",
        "\n",
        "            policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
        "            value_loss = F.mse_loss(out_value, value_targets)\n",
        "            loss = policy_loss + value_loss\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "    def learn(self):\n",
        "        for iteration in range(self.args['num_iterations']):\n",
        "            memory = []\n",
        "\n",
        "            self.model.eval()\n",
        "            for selfPlay_iteration in trange(self.args['num_selfPlay_iterations']):\n",
        "                memory += self.selfPlay()\n",
        "\n",
        "            self.model.train()\n",
        "            for epoch in trange(self.args['num_epochs']):\n",
        "                self.train(memory)\n",
        "\n",
        "            torch.save(self.model.state_dict(), f\"model_{iteration}_{self.game}.pt\")\n",
        "            torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}_{self.game}.pt\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MCTS &mdash; parallel"
      ],
      "metadata": {
        "id": "QVc1-WiS1k_O"
      },
      "id": "QVc1-WiS1k_O"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e997f3ea",
      "metadata": {
        "id": "e997f3ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1449f84-d92b-4289-e508-8939f93e5c38"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.35 ms (started: 2024-04-05 13:53:28 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class MCTSParallel:\n",
        "    def __init__(self, game, args, model):\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.model = model\n",
        "\n",
        "    @torch.no_grad()\n",
        "    def search(self, states, spGames):\n",
        "        policy, _ = self.model(\n",
        "            torch.tensor(self.game.get_encoded_state(states), device=self.model.device)\n",
        "        )\n",
        "        policy = torch.softmax(policy, axis=1).cpu().numpy()\n",
        "        policy = (1 - self.args['dirichlet_epsilon']) * policy + self.args['dirichlet_epsilon'] \\\n",
        "            * np.random.dirichlet([self.args['dirichlet_alpha']] * self.game.action_size, size=policy.shape[0])\n",
        "\n",
        "        for i, spg in enumerate(spGames):\n",
        "            spg_policy = policy[i]\n",
        "            valid_moves = self.game.get_valid_moves(states[i])\n",
        "            spg_policy *= valid_moves\n",
        "            spg_policy /= np.sum(spg_policy)\n",
        "\n",
        "            spg.root = Node(self.game, self.args, states[i], visit_count=1)\n",
        "            spg.root.expand(spg_policy)\n",
        "\n",
        "        for search in range(self.args['num_searches']):\n",
        "            for spg in spGames:\n",
        "                spg.node = None\n",
        "                node = spg.root\n",
        "\n",
        "                while node.is_fully_expanded():\n",
        "                    node = node.select()\n",
        "\n",
        "                value, is_terminal = self.game.get_value_and_terminated(node.state, node.action_taken)\n",
        "                value = self.game.get_opponent_value(value)\n",
        "\n",
        "                if is_terminal:\n",
        "                    node.backpropagate(value)\n",
        "\n",
        "                else:\n",
        "                    spg.node = node\n",
        "\n",
        "            expandable_spGames = [mappingIdx for mappingIdx in range(len(spGames)) if spGames[mappingIdx].node is not None]\n",
        "\n",
        "            if len(expandable_spGames) > 0:\n",
        "                states = np.stack([spGames[mappingIdx].node.state for mappingIdx in expandable_spGames])\n",
        "\n",
        "                policy, value = self.model(\n",
        "                    torch.tensor(self.game.get_encoded_state(states), device=self.model.device)\n",
        "                )\n",
        "                policy = torch.softmax(policy, axis=1).cpu().numpy()\n",
        "                value = value.cpu().numpy()\n",
        "\n",
        "            for i, mappingIdx in enumerate(expandable_spGames):\n",
        "                node = spGames[mappingIdx].node\n",
        "                spg_policy, spg_value = policy[i], value[i]\n",
        "\n",
        "                valid_moves = self.game.get_valid_moves(node.state)\n",
        "                spg_policy *= valid_moves\n",
        "                spg_policy /= np.sum(spg_policy)\n",
        "\n",
        "                node.expand(spg_policy)\n",
        "                node.backpropagate(spg_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### AlphaZero &mdash; parallel"
      ],
      "metadata": {
        "id": "CHym_voC1nbG"
      },
      "id": "CHym_voC1nbG"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7d0a5a7d",
      "metadata": {
        "id": "7d0a5a7d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "48788f3b-5e1b-4f57-ec05-3f65c93b88ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 2.22 ms (started: 2024-04-05 13:53:28 +00:00)\n"
          ]
        }
      ],
      "source": [
        "class AlphaZeroParallel:\n",
        "    def __init__(self, model, optimizer, game, args):\n",
        "        self.model = model\n",
        "        self.optimizer = optimizer\n",
        "        self.game = game\n",
        "        self.args = args\n",
        "        self.mcts = MCTSParallel(game, args, model)\n",
        "\n",
        "    def selfPlay(self):\n",
        "        return_memory = []\n",
        "        player = 1\n",
        "        spGames = [SPG(self.game) for spg in range(self.args['num_parallel_games'])]\n",
        "\n",
        "        while len(spGames) > 0:\n",
        "            states = np.stack([spg.state for spg in spGames])\n",
        "            neutral_states = self.game.change_perspective(states, player)\n",
        "\n",
        "            self.mcts.search(neutral_states, spGames)\n",
        "\n",
        "            for i in range(len(spGames))[::-1]:\n",
        "                spg = spGames[i]\n",
        "\n",
        "                action_probs = np.zeros(self.game.action_size)\n",
        "                for child in spg.root.children:\n",
        "                    action_probs[child.action_taken] = child.visit_count\n",
        "                action_probs /= np.sum(action_probs)\n",
        "\n",
        "                spg.memory.append((spg.root.state, action_probs, player))\n",
        "\n",
        "                temperature_action_probs = action_probs ** (1 / self.args['temperature'])\n",
        "                # Normalize temperature_action_probs so that its values sum to 1 by dividing it by its sum:\n",
        "                temperature_action_probs /= np.sum(temperature_action_probs) # Fixes: A ValueError is raised with the message \"probabilities do not sum to 1\".\n",
        "                action = np.random.choice(self.game.action_size, p=temperature_action_probs) # Divide temperature_action_probs with its sum in case of an error\n",
        "\n",
        "                spg.state = self.game.get_next_state(spg.state, action, player)\n",
        "\n",
        "                value, is_terminal = self.game.get_value_and_terminated(spg.state, action)\n",
        "\n",
        "                if is_terminal:\n",
        "                    for hist_neutral_state, hist_action_probs, hist_player in spg.memory:\n",
        "                        hist_outcome = value if hist_player == player else self.game.get_opponent_value(value)\n",
        "                        return_memory.append((\n",
        "                            self.game.get_encoded_state(hist_neutral_state),\n",
        "                            hist_action_probs,\n",
        "                            hist_outcome\n",
        "                        ))\n",
        "                    del spGames[i]\n",
        "\n",
        "            player = self.game.get_opponent(player)\n",
        "\n",
        "        return return_memory\n",
        "\n",
        "    def train(self, memory):\n",
        "        random.shuffle(memory)\n",
        "        for batchIdx in range(0, len(memory), self.args['batch_size']):\n",
        "            sample = memory[batchIdx:min(len(memory) - 1, batchIdx + self.args['batch_size'])] # Change to memory[batchIdx:batchIdx+self.args['batch_size']] in case of an error\n",
        "            state, policy_targets, value_targets = zip(*sample)\n",
        "\n",
        "            state, policy_targets, value_targets = np.array(state), np.array(policy_targets), np.array(value_targets).reshape(-1, 1)\n",
        "\n",
        "            state = torch.tensor(state, dtype=torch.float32, device=self.model.device)\n",
        "            policy_targets = torch.tensor(policy_targets, dtype=torch.float32, device=self.model.device)\n",
        "            value_targets = torch.tensor(value_targets, dtype=torch.float32, device=self.model.device)\n",
        "\n",
        "            out_policy, out_value = self.model(state)\n",
        "\n",
        "            policy_loss = F.cross_entropy(out_policy, policy_targets)\n",
        "            value_loss = F.mse_loss(out_value, value_targets)\n",
        "            loss = policy_loss + value_loss\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "    def learn(self):\n",
        "        for iteration in range(self.args['num_iterations']):\n",
        "            memory = []\n",
        "\n",
        "            self.model.eval()\n",
        "            for selfPlay_iteration in trange(self.args['num_selfPlay_iterations'] // self.args['num_parallel_games']):\n",
        "                memory += self.selfPlay()\n",
        "\n",
        "            self.model.train()\n",
        "            for epoch in trange(self.args['num_epochs']):\n",
        "                self.train(memory)\n",
        "\n",
        "            torch.save(self.model.state_dict(), f\"model_{iteration}_{self.game}.pt\")\n",
        "            torch.save(self.optimizer.state_dict(), f\"optimizer_{iteration}_{self.game}.pt\")\n",
        "\n",
        "class SPG:\n",
        "    def __init__(self, game):\n",
        "        self.state = game.get_initial_state()\n",
        "        self.memory = []\n",
        "        self.root = None\n",
        "        self.node = None"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train model\n",
        "\n"
      ],
      "metadata": {
        "id": "RMlEpgYE1t-n"
      },
      "id": "RMlEpgYE1t-n"
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltrh --time-style=full-iso > directory_listing.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fHKV-VwqS-NW",
        "outputId": "de9bce11-0dae-46c9-ee49-41f2e98891bb"
      },
      "id": "fHKV-VwqS-NW",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 105 ms (started: 2024-04-05 13:53:28 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "24bd91ef",
      "metadata": {
        "id": "24bd91ef",
        "outputId": "07ce9dd7-40ee-414f-bf5e-a5ba682b7e1b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 641 µs (started: 2024-04-05 13:53:28 +00:00)\n"
          ]
        }
      ],
      "source": [
        "def train_game(game_name: str):\n",
        "    game = globals()[game_name]()\n",
        "    print(f\"Training {game}...\")\n",
        "\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    num_resBlocks = CONFIG[CHOOSE_GAME][\"ResNet\"][\"num_resBlocks\"]\n",
        "    num_hidden = CONFIG[CHOOSE_GAME][\"ResNet\"][\"num_hidden\"]\n",
        "\n",
        "    model = ResNet(game, num_resBlocks, num_hidden, device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
        "\n",
        "    args = {\n",
        "        'C': 2,\n",
        "        'num_searches': 10,\n",
        "        'num_iterations': 1,\n",
        "        'num_selfPlay_iterations': 200,\n",
        "        'num_parallel_games': 100,\n",
        "        'num_epochs': 4,\n",
        "        'batch_size': 128,\n",
        "        'temperature': 1.25,\n",
        "        'dirichlet_epsilon': 0.25,\n",
        "        'dirichlet_alpha': 0.3\n",
        "    }\n",
        "\n",
        "    alphaZero = AlphaZeroParallel(model, optimizer, game, args)\n",
        "    alphaZero.learn()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "already_trained = []\n",
        "\n",
        "if RUN_LONG_TESTS:\n",
        "    # Train the simple games to test the harness\n",
        "    for game_name in CONFIG:\n",
        "        train_game(game_name)\n",
        "        already_trained.append(game_name)\n",
        "\n",
        "# Only train if we haven't already\n",
        "if CHOOSE_GAME not in already_trained:\n",
        "    train_game(CHOOSE_GAME)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "e7aeb62ef81a4710b19eec26f5b85b7a",
            "1aa7611748cf47779f19ae0d661c1bee",
            "5cc9b846cfe74c52af910b7fb2f07dc1",
            "87ec689147e7477cb6c39fa947b0491e",
            "f0eeaabcfaab41d791c1531bb622c48d",
            "4e7312e7b99845239c7e6122e17bb02b",
            "be3a2ec982444693b8a5bee9dfd7d367",
            "ad32b0b0cbe1447d8437f801fd27a492",
            "810c65b58f1f4dec82c86c1740d3eefb",
            "016d437807cd46a8899c06b58989e260",
            "b7155c00e66e4a139238a5576d0a8bf8",
            "de099e63a5d24866a486d9f546fe5374",
            "eef0a475a18d424cb96d614f96029099",
            "850d6a4f98124262b1869c079f551186",
            "67b8fddc479e4e3682b9cd6ba4771c7a",
            "55edc73b8b864fa2873b14312fd12fcd",
            "36b9affb6fcb4f659f20836215629dfd",
            "4e71ec21508a4d36b2ec63ad4ee2ff84",
            "7826d9fcd6ae4a9f8576ab0e41013c46",
            "68f9814e867b45b3a714716e9713130c",
            "96d8d22ad43f41c9a90e3a9176294c1e",
            "67df5fb8c1374fe3978d71944b339a75"
          ]
        },
        "id": "Hv5z2QbvU4J0",
        "outputId": "1c99dea9-6e70-4065-b359-2026c0a510fe"
      },
      "id": "Hv5z2QbvU4J0",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training ConnectFour...\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e7aeb62ef81a4710b19eec26f5b85b7a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/4 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "de099e63a5d24866a486d9f546fe5374"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 20.5 s (started: 2024-04-05 13:53:28 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls -ltrh --time-style=full-iso | diff directory_listing.txt - | grep -v directory_listing.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uNldfA1GoDQ5",
        "outputId": "ef960a70-fd23-4730-ac54-d69f2b9149e9"
      },
      "id": "uNldfA1GoDQ5",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1c1\n",
            "< total 78M\n",
            "---\n",
            "> total 109M\n",
            "10c10,12\n",
            "---\n",
            "> -rw-r--r-- 1 root root  11M 2024-04-05 13:53:49.432774176 +0000 model_0_ConnectFour.pt\n",
            "> -rw-r--r-- 1 root root  21M 2024-04-05 13:53:49.480778279 +0000 optimizer_0_ConnectFour.pt\n",
            "time: 105 ms (started: 2024-04-05 13:53:49 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Rest of the *10.Eval.ipynb* code -- we don't need it right now"
      ],
      "metadata": {
        "id": "kcvRmMw915lz"
      },
      "id": "kcvRmMw915lz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c470145",
      "metadata": {
        "scrolled": true,
        "id": "7c470145",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1d01f625-756e-417c-9ff1-4f9f4a568b33"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.04 ms (started: 2024-04-05 13:53:49 +00:00)\n"
          ]
        }
      ],
      "source": [
        "if False:\n",
        "  game = ConnectFour()\n",
        "  player = 1\n",
        "\n",
        "  args = {\n",
        "      'C': 2,\n",
        "      'num_searches': 10,\n",
        "      'dirichlet_epsilon': 0.,\n",
        "      'dirichlet_alpha': 0.3\n",
        "  }\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  model = ResNet(game, 9, 128, device)\n",
        "  model.load_state_dict(torch.load(\"model_7_ConnectFour.pt\", map_location=device))\n",
        "  model.eval()\n",
        "\n",
        "  mcts = MCTS(game, args, model)\n",
        "\n",
        "  state = game.get_initial_state()\n",
        "\n",
        "\n",
        "  while True:\n",
        "      print(state)\n",
        "\n",
        "      if player == 1:\n",
        "          valid_moves = game.get_valid_moves(state)\n",
        "          print(\"valid_moves\", [i for i in range(game.action_size) if valid_moves[i] == 1])\n",
        "          action = int(input(f\"{player}:\"))\n",
        "\n",
        "          if valid_moves[action] == 0:\n",
        "              print(\"action not valid\")\n",
        "              continue\n",
        "\n",
        "      else:\n",
        "          neutral_state = game.change_perspective(state, player)\n",
        "          mcts_probs = mcts.search(neutral_state)\n",
        "          action = np.argmax(mcts_probs)\n",
        "\n",
        "      state = game.get_next_state(state, action, player)\n",
        "\n",
        "      value, is_terminal = game.get_value_and_terminated(state, action)\n",
        "\n",
        "      if is_terminal:\n",
        "          print(state)\n",
        "          if value == 1:\n",
        "              print(player, \"won\")\n",
        "          else:\n",
        "              print(\"draw\")\n",
        "          break\n",
        "\n",
        "      player = game.get_opponent(player)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c3528828",
      "metadata": {
        "id": "c3528828",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ac73de3-81b6-4b94-e6de-f4cb4c10d1c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 1.3 ms (started: 2024-04-05 13:53:49 +00:00)\n"
          ]
        }
      ],
      "source": [
        "if False:\n",
        "  import kaggle_environments\n",
        "  print(kaggle_environments.__version__)\n",
        "\n",
        "  class KaggleAgent:\n",
        "      def __init__(self, model, game, args):\n",
        "          self.model = model\n",
        "          self.game = game\n",
        "          self.args = args\n",
        "          if self.args['search']:\n",
        "              self.mcts = MCTS(self.game, self.args, self.model)\n",
        "\n",
        "      def run(self, obs, conf):\n",
        "          player = obs['mark'] if obs['mark'] == 1 else -1\n",
        "          state = np.array(obs['board']).reshape(self.game.row_count, self.game.column_count)\n",
        "          state[state==2] = -1\n",
        "\n",
        "          state = self.game.change_perspective(state, player)\n",
        "\n",
        "          if self.args['search']:\n",
        "              policy = self.mcts.search(state)\n",
        "\n",
        "          else:\n",
        "              policy, _ = self.model.predict(state, augment=self.args['augment']) # Not working with the video's implementation\n",
        "\n",
        "          valid_moves = self.game.get_valid_moves(state)\n",
        "          policy *= valid_moves\n",
        "          policy /= np.sum(policy)\n",
        "\n",
        "          if self.args['temperature'] == 0:\n",
        "              action = int(np.argmax(policy))\n",
        "          elif self.args['temperature'] == float('inf'):\n",
        "              action = np.random.choice([r for r in range(self.game.action_size) if policy[r] > 0])\n",
        "          else:\n",
        "              policy = policy ** (1 / self.args['temperature'])\n",
        "              policy /= np.sum(policy)\n",
        "              action = np.random.choice(self.game.action_size, p=policy)\n",
        "\n",
        "          return action\n",
        "\n",
        "  game = TicTacToe()\n",
        "\n",
        "  args = {\n",
        "      'C': 2,\n",
        "      'num_searches': 10,\n",
        "      'dirichlet_epsilon': 0.1,\n",
        "      'dirichlet_alpha': 0.3,\n",
        "      'search': True,\n",
        "      'temperature': 0,\n",
        "  }\n",
        "\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "  model = ResNet(game, 4, 64, device)\n",
        "  model.load_state_dict(torch.load(\"model_2.pt\", map_location=device))\n",
        "  model.eval()\n",
        "\n",
        "  env = kaggle_environments.make(\"tictactoe\")\n",
        "\n",
        "  player1 = KaggleAgent(model, game, args)\n",
        "  player2 = KaggleAgent(model, game, args)\n",
        "\n",
        "  players = [player1.run, player2.run]\n",
        "\n",
        "  env.run(players)\n",
        "\n",
        "  env.render(mode=\"ipython\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "myenv",
      "language": "python",
      "name": "myenv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "2177f1ca12c1330a133c1d40b46100b268ab447cddcbdfdc0c7b2b7e4840e700"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "u8LIKCjU1KPw",
        "h-Fr1Dey1Y6D",
        "-MtBUrqH1eC6",
        "CHym_voC1nbG"
      ],
      "machine_shape": "hm",
      "gpuType": "V100",
      "toc_visible": true,
      "include_colab_link": true
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "e7aeb62ef81a4710b19eec26f5b85b7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_1aa7611748cf47779f19ae0d661c1bee",
              "IPY_MODEL_5cc9b846cfe74c52af910b7fb2f07dc1",
              "IPY_MODEL_87ec689147e7477cb6c39fa947b0491e"
            ],
            "layout": "IPY_MODEL_f0eeaabcfaab41d791c1531bb622c48d"
          }
        },
        "1aa7611748cf47779f19ae0d661c1bee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4e7312e7b99845239c7e6122e17bb02b",
            "placeholder": "​",
            "style": "IPY_MODEL_be3a2ec982444693b8a5bee9dfd7d367",
            "value": "100%"
          }
        },
        "5cc9b846cfe74c52af910b7fb2f07dc1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ad32b0b0cbe1447d8437f801fd27a492",
            "max": 2,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_810c65b58f1f4dec82c86c1740d3eefb",
            "value": 2
          }
        },
        "87ec689147e7477cb6c39fa947b0491e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_016d437807cd46a8899c06b58989e260",
            "placeholder": "​",
            "style": "IPY_MODEL_b7155c00e66e4a139238a5576d0a8bf8",
            "value": " 2/2 [00:15&lt;00:00,  7.85s/it]"
          }
        },
        "f0eeaabcfaab41d791c1531bb622c48d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e7312e7b99845239c7e6122e17bb02b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "be3a2ec982444693b8a5bee9dfd7d367": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ad32b0b0cbe1447d8437f801fd27a492": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "810c65b58f1f4dec82c86c1740d3eefb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "016d437807cd46a8899c06b58989e260": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7155c00e66e4a139238a5576d0a8bf8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "de099e63a5d24866a486d9f546fe5374": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eef0a475a18d424cb96d614f96029099",
              "IPY_MODEL_850d6a4f98124262b1869c079f551186",
              "IPY_MODEL_67b8fddc479e4e3682b9cd6ba4771c7a"
            ],
            "layout": "IPY_MODEL_55edc73b8b864fa2873b14312fd12fcd"
          }
        },
        "eef0a475a18d424cb96d614f96029099": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36b9affb6fcb4f659f20836215629dfd",
            "placeholder": "​",
            "style": "IPY_MODEL_4e71ec21508a4d36b2ec63ad4ee2ff84",
            "value": "100%"
          }
        },
        "850d6a4f98124262b1869c079f551186": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7826d9fcd6ae4a9f8576ab0e41013c46",
            "max": 4,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_68f9814e867b45b3a714716e9713130c",
            "value": 4
          }
        },
        "67b8fddc479e4e3682b9cd6ba4771c7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_96d8d22ad43f41c9a90e3a9176294c1e",
            "placeholder": "​",
            "style": "IPY_MODEL_67df5fb8c1374fe3978d71944b339a75",
            "value": " 4/4 [00:02&lt;00:00,  1.96it/s]"
          }
        },
        "55edc73b8b864fa2873b14312fd12fcd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36b9affb6fcb4f659f20836215629dfd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4e71ec21508a4d36b2ec63ad4ee2ff84": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7826d9fcd6ae4a9f8576ab0e41013c46": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "68f9814e867b45b3a714716e9713130c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "96d8d22ad43f41c9a90e3a9176294c1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67df5fb8c1374fe3978d71944b339a75": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}